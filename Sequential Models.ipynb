{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orOXX7R5Uy6w"
   },
   "source": [
    "### Sequential Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Y8KilLZUy6x"
   },
   "source": [
    "### Obbjectives:\n",
    "- Practice creating sequential models with Keras for different tasks:\n",
    "    - Classification\n",
    "    - Regression\n",
    "- Test different architectures: wide vs. deep, complex/simple models\n",
    "- Learn how to use different techniques to fight with underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByQjiq0zUy6y"
   },
   "source": [
    "### COVID-19 Real World Worry Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GNNJnGjUy6z"
   },
   "source": [
    "- In this task, we will build a network to predict the levels of worry people feel about Covid-19. \n",
    "- The dataset contains a column \"worry\", which gives the level of worry each participant in this study reported. Let's create a `binary` variable called \"worry_level\", which is set to 1 (i.e. high) if `worry>5`, otherwise, 0 (i.e. low)\n",
    "- The dataset also contains two textual columns: `text_short` and `text_long`, which describes how each participant feels about the pandemic. For this assignment, we'll only use `text_short` column to predict the level of worry.\n",
    "- The details of the dataset can be found at https://arxiv.org/abs/2004.04225. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:39:45.206506Z",
     "start_time": "2020-10-19T16:39:45.163341Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "dwIeG8zXUy6z",
    "outputId": "199527e0-746d-4172-c54f-6b4176e49adb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>worry</th>\n",
       "      <th>chosen_emotion</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>sadness</th>\n",
       "      <th>happiness</th>\n",
       "      <th>relaxation</th>\n",
       "      <th>desire</th>\n",
       "      <th>text_long</th>\n",
       "      <th>text_short</th>\n",
       "      <th>worry_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>It is less an much an issue of how it affects ...</td>\n",
       "      <td>It is very easy! Stay inside so you are not sp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>I am concerned that the true impact of the cur...</td>\n",
       "      <td>Things are difficult now, but we must all pull...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Relaxation</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Personally, I am fairly calm about the corona ...</td>\n",
       "      <td>People should try and remain calm, as panic wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Relaxation</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>In this very moment as I am fortunate to be ab...</td>\n",
       "      <td>Fortunate to feel calm and relaxed but worried...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>I am more worried about getting access to my n...</td>\n",
       "      <td>Not being able to cuddle my family sucks!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  worry chosen_emotion  anger  disgust  fear  anxiety  sadness  \\\n",
       "0   1      3        Sadness      5        5     3        7        7   \n",
       "1   2      8        Anxiety      6        7     7        8        6   \n",
       "2   3      4     Relaxation      1        1     2        2        4   \n",
       "3   4      6     Relaxation      4        2     3        4        1   \n",
       "4   5      6        Anxiety      2        2     5        5        5   \n",
       "\n",
       "   happiness  relaxation  desire  \\\n",
       "0          2           4       5   \n",
       "1          4           3       1   \n",
       "2          7           7       2   \n",
       "3          6           7       3   \n",
       "4          4           4       4   \n",
       "\n",
       "                                           text_long  \\\n",
       "0  It is less an much an issue of how it affects ...   \n",
       "1  I am concerned that the true impact of the cur...   \n",
       "2  Personally, I am fairly calm about the corona ...   \n",
       "3  In this very moment as I am fortunate to be ab...   \n",
       "4  I am more worried about getting access to my n...   \n",
       "\n",
       "                                          text_short  worry_level  \n",
       "0  It is very easy! Stay inside so you are not sp...            0  \n",
       "1  Things are difficult now, but we must all pull...            1  \n",
       "2  People should try and remain calm, as panic wi...            0  \n",
       "3  Fortunate to feel calm and relaxed but worried...            1  \n",
       "4          Not being able to cuddle my family sucks!            1  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "data = pd.read_csv(\"RWWD.csv\")\n",
    "    \n",
    "data[\"worry_level\"] = data.worry.apply(lambda x: 1 if x>5 else 0)\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-EZV9yiUy64"
   },
   "source": [
    "### Task 1: Prepare data\n",
    "- We need to vectorize `text_short` column using a classical approach called `TF-IDF (Term Frequency and Inverse Document Frequency)`. \n",
    "- After vectorization, you'll get an array, where each document in `text_short` column is represented as a row and each word is a column. If a word (say $j$) appears in the document (say $i$), the value at $(i, j)$ is the `TF-IDF` weight of the word in the document.\n",
    "- Save the result of vectorization as a `dense array, not a sparse array`. When fitting Keras model, dense arrays are expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:05.291292Z",
     "start_time": "2020-10-19T16:21:04.915987Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UU-cbHPLUy65",
    "outputId": "53359dfd-2d01-40b1-b4aa-a63a3de0d505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"It is very easy! Stay inside so you are not spreading to vulnerable people. If you have to work, do not use public transport, don't travel share and work at home if your job permits. \"\n",
      " 'Things are difficult now, but we must all pull together to get through this.  We must remember the things we are going through now to ensure the decisions we make in future help us should a similar situation arise again. '\n",
      " 'People should try and remain calm, as panic will only make the situation worse'\n",
      " ... 'Please stay home to keep us all alive '\n",
      " \"There are people who still believe it is okay to leave outside even after the strict lockdown rules being set in stone even if the weather is nice outside no excuse your just putting yourself in danger and other's those who own garden can spend time flowering sunbathing etc. \"\n",
      " 'This is the worst. ']\n",
      "      000   10  100   12   14   15  15th   16        19  1918 ...   young  \\\n",
      "0     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "1     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "3     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.204764   0.0 ...     0.0   \n",
      "4     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "5     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "6     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "7     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "8     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "9     0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "10    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "11    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "12    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "13    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "14    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "15    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "16    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "17    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "18    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "19    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "20    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "21    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "22    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "23    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "24    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "25    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "26    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "27    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "28    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "29    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "...   ...  ...  ...  ...  ...  ...   ...  ...       ...   ... ...     ...   \n",
      "2461  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2462  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2463  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2464  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2465  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2466  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2467  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2468  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2469  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2470  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2471  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2472  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2473  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2474  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2475  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2476  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2477  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2478  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2479  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.207189   0.0 ...     0.0   \n",
      "2480  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2481  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2482  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2483  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2484  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2485  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2486  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2487  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2488  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2489  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "2490  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.000000   0.0 ...     0.0   \n",
      "\n",
      "          your  yours  yourself  yourselves  youth  yummy  zero  zombie  zoo  \n",
      "0     0.142012    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "1     0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2     0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "3     0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "4     0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "5     0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "6     0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "7     0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "8     0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "9     0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "10    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "11    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "12    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "13    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "14    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "15    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "16    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "17    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "18    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "19    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "20    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "21    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "22    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "23    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "24    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "25    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "26    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "27    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "28    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "29    0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "...        ...    ...       ...         ...    ...    ...   ...     ...  ...  \n",
      "2461  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2462  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2463  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2464  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2465  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2466  0.000000    0.0  0.203014         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2467  0.224738    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2468  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2469  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2470  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2471  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2472  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2473  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2474  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2475  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2476  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2477  0.250816    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2478  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2479  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2480  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2481  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2482  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2483  0.155450    0.0  0.210978         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2484  0.123720    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2485  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2486  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2487  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2488  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2489  0.109009    0.0  0.147948         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "2490  0.000000    0.0  0.000000         0.0    0.0    0.0   0.0     0.0  0.0  \n",
      "\n",
      "[2491 rows x 4402 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "# Write script to vectorize text_short column\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "col=data.iloc[:,12]\n",
    "arrs=col.values\n",
    "print(arrs)\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word')\n",
    "tfidf_arrs = tfidfvectorizer.fit_transform(arrs)\n",
    "tfidf_tokens = tfidfvectorizer.get_feature_names()\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_arrs.toarray(),columns = tfidf_tokens)\n",
    "\n",
    "print(df_tfidfvect)\n",
    "\n",
    "\n",
    "         \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sA3ge5suUy6_"
   },
   "source": [
    "### Task 2: Create seqential models to classify `short_text` into `worry_level` in different architectures\n",
    "- After vectorization, create a neural network model which takes the vectors of `short_text` as an input and predicts the binary `worry_level`.\n",
    "- Create three different sequential models as shown in the figure below.\n",
    "    1. Model A: This model only has one hidden layer with 256 units\n",
    "    2. Model B: This model only has one hidden layer with 128 units\n",
    "    3. Model C: This model has two hidden layers. The first hidden layer has 128 units and the second hidden layer has 32 units.\n",
    "- Set aside 20% of them as the test subset (i.e. `x_test, y_test`). From the remaining samples, set aside 20% of the samples for validation (i.e. `x_val, y_val`)\n",
    "- Define a function `fit_model(model, x_train, y_train, x_val, y_val, x_test, y_test)`, and use this function to train each `model` as follows:\n",
    "    - Train with appropriate hyperparameters, including `optimizer`, `loss function`, `epochs`, and `batch_size`\n",
    "    - After training, calculate the loss and accuracy of each model on the test dataset (i.e. `x_test, y_test`) and print them out\n",
    "    - Return training history  \n",
    "- Plot validation loss and validation accuracy vs. epoches from the training histories of these three models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:06.962320Z",
     "start_time": "2020-10-19T16:21:06.957496Z"
    },
    "collapsed": true,
    "id": "HzRutYO7Uy6_"
   },
   "outputs": [],
   "source": [
    "# fix random number so model results can be replicated\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_random_seed # tf version = 1.15.0 \n",
    "\n",
    "seed(123)\n",
    "set_random_seed(231)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:07.799269Z",
     "start_time": "2020-10-19T16:21:07.620224Z"
    },
    "collapsed": true,
    "id": "wc1yRVR0Uy7D"
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "\n",
    "train_x_1 =  df_tfidfvect.iloc[:int(df_tfidfvect.shape[0] * 0.8), :]\n",
    "x_test=  np.array(df_tfidfvect.iloc[int(df_tfidfvect.shape[0] * 0.8):, :])\n",
    "train_y_1 = data.iloc[:int(data.shape[0] * 0.8), -1]\n",
    "y_test= np.array(data.iloc[int(data.shape[0] * 0.8):, -1])\n",
    "\n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TPBbNrtIUy7H",
    "outputId": "c4f9c4a4-d857-4751-a0f7-d027bfe2ecfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1594, 4402) (398, 4402) (499, 4402)\n"
     ]
    }
   ],
   "source": [
    "x_val = np.array(train_x_1[:int(train_x_1.shape[0] * 0.2)])\n",
    "x_train = np.array(train_x_1[int(train_x_1.shape[0] * 0.2):])\n",
    "print(x_train.shape,x_val.shape,x_test.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rk-W7eKCUy7K",
    "outputId": "8791e1f9-4b4a-45e7-8a1a-279b6b2393a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1594,) (398,) (499,)\n"
     ]
    }
   ],
   "source": [
    "y_val = np.array(train_y_1[:int(train_y_1.shape[0] * 0.2)])\n",
    "y_train = np.array(train_y_1[int(train_y_1.shape[0] * 0.2):])\n",
    "print(y_train.shape,y_val.shape,y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:08.985758Z",
     "start_time": "2020-10-19T16:21:08.739921Z"
    },
    "collapsed": true,
    "id": "XC3b4_ZaUy7N"
   },
   "outputs": [],
   "source": [
    "# Define model A\n",
    "\n",
    "# add your code here\n",
    "modela = Sequential()\n",
    "modela.add(Dense(units=256, activation='relu',input_dim = 4402))   \n",
    "modela.add(Dense(units=1, activation='sigmoid')) \n",
    "\n",
    "# Display model graph - optional\n",
    "# G = model_to_dot (modela)\n",
    "# Image (G.create (prog = \"dot\", format = \"png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjsjTpiRUy7Q",
    "outputId": "45e402d3-68ff-4604-b045-20a8ee596e6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               1127168   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,127,425\n",
      "Trainable params: 1,127,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modela.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:09.945699Z",
     "start_time": "2020-10-19T16:21:09.707793Z"
    },
    "collapsed": true,
    "id": "kjOt25XUUy7T"
   },
   "outputs": [],
   "source": [
    "# Define Model B\n",
    "\n",
    "# add your code here\n",
    "modelb = Sequential()\n",
    "modelb.add(Dense(units=128, activation='relu',input_dim = 4402))   \n",
    "modelb.add(Dense(units=1, activation='sigmoid')) \n",
    "\n",
    "# Display model graph\n",
    "#G = model_to_dot (modelb)\n",
    "#Image (G.create (prog = \"dot\", format = \"png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvIWc1Bj20PT",
    "outputId": "7a45c069-f87e-44be-fcb3-be6a9e314ad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               563584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 563,713\n",
      "Trainable params: 563,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:10.607957Z",
     "start_time": "2020-10-19T16:21:10.363868Z"
    },
    "collapsed": true,
    "id": "B2iF0dgwUy7W"
   },
   "outputs": [],
   "source": [
    "# Define Model C\n",
    "\n",
    "# add your code here\n",
    "modelc = Sequential()\n",
    "modelc.add(Dense(units=128, activation='relu',input_dim =4402 ))   \n",
    "modelc.add(Dense(units=32, activation='relu'))\n",
    "modelc.add(Dense(units=1, activation='sigmoid'))  \n",
    "\n",
    "# Display model graph\n",
    "#G = model_to_dot (modelc)\n",
    "#Image (G.create (prog = \"dot\", format = \"png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9_owIIZ25av",
    "outputId": "d176f55f-d909-468e-f5b3-b7ebe3d07e03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 128)               563584    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 567,745\n",
      "Trainable params: 567,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:11.329038Z",
     "start_time": "2020-10-19T16:21:11.196036Z"
    },
    "collapsed": true,
    "id": "X5bY2r-XUy7Z"
   },
   "outputs": [],
   "source": [
    "# Split training dataset into train, test and validation subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# add your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:11.865120Z",
     "start_time": "2020-10-19T16:21:11.860118Z"
    },
    "collapsed": true,
    "id": "pkJwOIW-Uy7c"
   },
   "outputs": [],
   "source": [
    "# Define fit_model function\n",
    "def fit_model(model, x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "    '''Input: model, x_train, y_train, x_val, y_val, x_test, y_test'''\n",
    "    '''Output: training history'''\n",
    "    \n",
    "    history = None\n",
    "\n",
    "\n",
    "    model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train, validation_data = (x_val, y_val),\n",
    "                     epochs=100, batch_size=128,verbose=1)\n",
    "    \n",
    "    # please print out the performance on test subset\n",
    "    score = model.evaluate(x_test, y_test, batch_size=128,verbose=1)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:28.348200Z",
     "start_time": "2020-10-19T16:21:12.332172Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmX7JrrPUy7f",
    "outputId": "4cc2841e-2110-4a61-edae-e7d0f88d7a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1594 samples, validate on 398 samples\n",
      "Epoch 1/100\n",
      "1594/1594 [==============================] - 1s 611us/step - loss: 0.6904 - acc: 0.5841 - val_loss: 0.6815 - val_acc: 0.7864\n",
      "Epoch 2/100\n",
      "1594/1594 [==============================] - 0s 124us/step - loss: 0.6754 - acc: 0.7854 - val_loss: 0.6670 - val_acc: 0.7915\n",
      "Epoch 3/100\n",
      "1594/1594 [==============================] - 0s 128us/step - loss: 0.6618 - acc: 0.7867 - val_loss: 0.6537 - val_acc: 0.7915\n",
      "Epoch 4/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.6492 - acc: 0.7867 - val_loss: 0.6414 - val_acc: 0.7915\n",
      "Epoch 5/100\n",
      "1594/1594 [==============================] - 0s 118us/step - loss: 0.6375 - acc: 0.7867 - val_loss: 0.6299 - val_acc: 0.7915\n",
      "Epoch 6/100\n",
      "1594/1594 [==============================] - 0s 138us/step - loss: 0.6267 - acc: 0.7867 - val_loss: 0.6194 - val_acc: 0.7915\n",
      "Epoch 7/100\n",
      "1594/1594 [==============================] - 0s 134us/step - loss: 0.6166 - acc: 0.7867 - val_loss: 0.6098 - val_acc: 0.7915\n",
      "Epoch 8/100\n",
      "1594/1594 [==============================] - 0s 118us/step - loss: 0.6076 - acc: 0.7867 - val_loss: 0.6006 - val_acc: 0.7915\n",
      "Epoch 9/100\n",
      "1594/1594 [==============================] - 0s 116us/step - loss: 0.5990 - acc: 0.7867 - val_loss: 0.5922 - val_acc: 0.7915\n",
      "Epoch 10/100\n",
      "1594/1594 [==============================] - 0s 115us/step - loss: 0.5910 - acc: 0.7867 - val_loss: 0.5846 - val_acc: 0.7915\n",
      "Epoch 11/100\n",
      "1594/1594 [==============================] - 0s 124us/step - loss: 0.5839 - acc: 0.7867 - val_loss: 0.5776 - val_acc: 0.7915\n",
      "Epoch 12/100\n",
      "1594/1594 [==============================] - 0s 135us/step - loss: 0.5774 - acc: 0.7867 - val_loss: 0.5712 - val_acc: 0.7915\n",
      "Epoch 13/100\n",
      "1594/1594 [==============================] - 0s 133us/step - loss: 0.5715 - acc: 0.7867 - val_loss: 0.5656 - val_acc: 0.7915\n",
      "Epoch 14/100\n",
      "1594/1594 [==============================] - 0s 130us/step - loss: 0.5662 - acc: 0.7867 - val_loss: 0.5602 - val_acc: 0.7915\n",
      "Epoch 15/100\n",
      "1594/1594 [==============================] - 0s 125us/step - loss: 0.5612 - acc: 0.7867 - val_loss: 0.5555 - val_acc: 0.7915\n",
      "Epoch 16/100\n",
      "1594/1594 [==============================] - 0s 125us/step - loss: 0.5569 - acc: 0.7867 - val_loss: 0.5513 - val_acc: 0.7915\n",
      "Epoch 17/100\n",
      "1594/1594 [==============================] - 0s 122us/step - loss: 0.5530 - acc: 0.7867 - val_loss: 0.5474 - val_acc: 0.7915\n",
      "Epoch 18/100\n",
      "1594/1594 [==============================] - 0s 118us/step - loss: 0.5494 - acc: 0.7867 - val_loss: 0.5440 - val_acc: 0.7915\n",
      "Epoch 19/100\n",
      "1594/1594 [==============================] - 0s 122us/step - loss: 0.5462 - acc: 0.7867 - val_loss: 0.5409 - val_acc: 0.7915\n",
      "Epoch 20/100\n",
      "1594/1594 [==============================] - 0s 120us/step - loss: 0.5433 - acc: 0.7867 - val_loss: 0.5379 - val_acc: 0.7915\n",
      "Epoch 21/100\n",
      "1594/1594 [==============================] - 0s 124us/step - loss: 0.5406 - acc: 0.7867 - val_loss: 0.5352 - val_acc: 0.7915\n",
      "Epoch 22/100\n",
      "1594/1594 [==============================] - 0s 128us/step - loss: 0.5382 - acc: 0.7867 - val_loss: 0.5330 - val_acc: 0.7915\n",
      "Epoch 23/100\n",
      "1594/1594 [==============================] - 0s 141us/step - loss: 0.5361 - acc: 0.7867 - val_loss: 0.5308 - val_acc: 0.7915\n",
      "Epoch 24/100\n",
      "1594/1594 [==============================] - 0s 126us/step - loss: 0.5342 - acc: 0.7867 - val_loss: 0.5288 - val_acc: 0.7915\n",
      "Epoch 25/100\n",
      "1594/1594 [==============================] - 0s 120us/step - loss: 0.5324 - acc: 0.7867 - val_loss: 0.5271 - val_acc: 0.7915\n",
      "Epoch 26/100\n",
      "1594/1594 [==============================] - 0s 133us/step - loss: 0.5308 - acc: 0.7867 - val_loss: 0.5255 - val_acc: 0.7915\n",
      "Epoch 27/100\n",
      "1594/1594 [==============================] - 0s 138us/step - loss: 0.5294 - acc: 0.7867 - val_loss: 0.5241 - val_acc: 0.7915\n",
      "Epoch 28/100\n",
      "1594/1594 [==============================] - 0s 133us/step - loss: 0.5281 - acc: 0.7867 - val_loss: 0.5228 - val_acc: 0.7915\n",
      "Epoch 29/100\n",
      "1594/1594 [==============================] - 0s 139us/step - loss: 0.5269 - acc: 0.7867 - val_loss: 0.5216 - val_acc: 0.7915\n",
      "Epoch 30/100\n",
      "1594/1594 [==============================] - 0s 148us/step - loss: 0.5259 - acc: 0.7867 - val_loss: 0.5206 - val_acc: 0.7915\n",
      "Epoch 31/100\n",
      "1594/1594 [==============================] - 0s 135us/step - loss: 0.5250 - acc: 0.7867 - val_loss: 0.5197 - val_acc: 0.7915\n",
      "Epoch 32/100\n",
      "1594/1594 [==============================] - 0s 128us/step - loss: 0.5241 - acc: 0.7867 - val_loss: 0.5188 - val_acc: 0.7915\n",
      "Epoch 33/100\n",
      "1594/1594 [==============================] - 0s 136us/step - loss: 0.5234 - acc: 0.7867 - val_loss: 0.5181 - val_acc: 0.7915\n",
      "Epoch 34/100\n",
      "1594/1594 [==============================] - 0s 141us/step - loss: 0.5227 - acc: 0.7867 - val_loss: 0.5174 - val_acc: 0.7915\n",
      "Epoch 35/100\n",
      "1594/1594 [==============================] - 0s 126us/step - loss: 0.5221 - acc: 0.7867 - val_loss: 0.5168 - val_acc: 0.7915\n",
      "Epoch 36/100\n",
      "1594/1594 [==============================] - 0s 118us/step - loss: 0.5216 - acc: 0.7867 - val_loss: 0.5162 - val_acc: 0.7915\n",
      "Epoch 37/100\n",
      "1594/1594 [==============================] - 0s 121us/step - loss: 0.5211 - acc: 0.7867 - val_loss: 0.5157 - val_acc: 0.7915\n",
      "Epoch 38/100\n",
      "1594/1594 [==============================] - 0s 121us/step - loss: 0.5206 - acc: 0.7867 - val_loss: 0.5152 - val_acc: 0.7915\n",
      "Epoch 39/100\n",
      "1594/1594 [==============================] - 0s 128us/step - loss: 0.5202 - acc: 0.7867 - val_loss: 0.5148 - val_acc: 0.7915\n",
      "Epoch 40/100\n",
      "1594/1594 [==============================] - 0s 128us/step - loss: 0.5199 - acc: 0.7867 - val_loss: 0.5144 - val_acc: 0.7915\n",
      "Epoch 41/100\n",
      "1594/1594 [==============================] - 0s 133us/step - loss: 0.5195 - acc: 0.7867 - val_loss: 0.5141 - val_acc: 0.7915\n",
      "Epoch 42/100\n",
      "1594/1594 [==============================] - 0s 117us/step - loss: 0.5192 - acc: 0.7867 - val_loss: 0.5138 - val_acc: 0.7915\n",
      "Epoch 43/100\n",
      "1594/1594 [==============================] - 0s 126us/step - loss: 0.5190 - acc: 0.7867 - val_loss: 0.5135 - val_acc: 0.7915\n",
      "Epoch 44/100\n",
      "1594/1594 [==============================] - 0s 124us/step - loss: 0.5187 - acc: 0.7867 - val_loss: 0.5133 - val_acc: 0.7915\n",
      "Epoch 45/100\n",
      "1594/1594 [==============================] - 0s 135us/step - loss: 0.5185 - acc: 0.7867 - val_loss: 0.5130 - val_acc: 0.7915\n",
      "Epoch 46/100\n",
      "1594/1594 [==============================] - 0s 126us/step - loss: 0.5183 - acc: 0.7867 - val_loss: 0.5128 - val_acc: 0.7915\n",
      "Epoch 47/100\n",
      "1594/1594 [==============================] - 0s 134us/step - loss: 0.5181 - acc: 0.7867 - val_loss: 0.5127 - val_acc: 0.7915\n",
      "Epoch 48/100\n",
      "1594/1594 [==============================] - 0s 120us/step - loss: 0.5180 - acc: 0.7867 - val_loss: 0.5125 - val_acc: 0.7915\n",
      "Epoch 49/100\n",
      "1594/1594 [==============================] - 0s 120us/step - loss: 0.5178 - acc: 0.7867 - val_loss: 0.5123 - val_acc: 0.7915\n",
      "Epoch 50/100\n",
      "1594/1594 [==============================] - 0s 146us/step - loss: 0.5177 - acc: 0.7867 - val_loss: 0.5122 - val_acc: 0.7915\n",
      "Epoch 51/100\n",
      "1594/1594 [==============================] - 0s 141us/step - loss: 0.5176 - acc: 0.7867 - val_loss: 0.5120 - val_acc: 0.7915\n",
      "Epoch 52/100\n",
      "1594/1594 [==============================] - 0s 121us/step - loss: 0.5174 - acc: 0.7867 - val_loss: 0.5119 - val_acc: 0.7915\n",
      "Epoch 53/100\n",
      "1594/1594 [==============================] - 0s 120us/step - loss: 0.5174 - acc: 0.7867 - val_loss: 0.5118 - val_acc: 0.7915\n",
      "Epoch 54/100\n",
      "1594/1594 [==============================] - 0s 128us/step - loss: 0.5172 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 55/100\n",
      "1594/1594 [==============================] - 0s 139us/step - loss: 0.5172 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 56/100\n",
      "1594/1594 [==============================] - 0s 129us/step - loss: 0.5171 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 57/100\n",
      "1594/1594 [==============================] - 0s 123us/step - loss: 0.5170 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 58/100\n",
      "1594/1594 [==============================] - 0s 122us/step - loss: 0.5170 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 59/100\n",
      "1594/1594 [==============================] - 0s 123us/step - loss: 0.5169 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594/1594 [==============================] - 0s 132us/step - loss: 0.5168 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 61/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5168 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 62/100\n",
      "1594/1594 [==============================] - 0s 138us/step - loss: 0.5167 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "Epoch 63/100\n",
      "1594/1594 [==============================] - 0s 142us/step - loss: 0.5166 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "Epoch 64/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5166 - acc: 0.7867 - val_loss: 0.5111 - val_acc: 0.7915\n",
      "Epoch 65/100\n",
      "1594/1594 [==============================] - 0s 122us/step - loss: 0.5166 - acc: 0.7867 - val_loss: 0.5111 - val_acc: 0.7915\n",
      "Epoch 66/100\n",
      "1594/1594 [==============================] - 0s 118us/step - loss: 0.5165 - acc: 0.7867 - val_loss: 0.5110 - val_acc: 0.7915\n",
      "Epoch 67/100\n",
      "1594/1594 [==============================] - 0s 118us/step - loss: 0.5165 - acc: 0.7867 - val_loss: 0.5110 - val_acc: 0.7915\n",
      "Epoch 68/100\n",
      "1594/1594 [==============================] - 0s 138us/step - loss: 0.5164 - acc: 0.7867 - val_loss: 0.5110 - val_acc: 0.7915\n",
      "Epoch 69/100\n",
      "1594/1594 [==============================] - 0s 160us/step - loss: 0.5164 - acc: 0.7867 - val_loss: 0.5109 - val_acc: 0.7915\n",
      "Epoch 70/100\n",
      "1594/1594 [==============================] - 0s 121us/step - loss: 0.5163 - acc: 0.7867 - val_loss: 0.5109 - val_acc: 0.7915\n",
      "Epoch 71/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5163 - acc: 0.7867 - val_loss: 0.5109 - val_acc: 0.7915\n",
      "Epoch 72/100\n",
      "1594/1594 [==============================] - 0s 125us/step - loss: 0.5163 - acc: 0.7867 - val_loss: 0.5109 - val_acc: 0.7915\n",
      "Epoch 73/100\n",
      "1594/1594 [==============================] - 0s 120us/step - loss: 0.5162 - acc: 0.7867 - val_loss: 0.5108 - val_acc: 0.7915\n",
      "Epoch 74/100\n",
      "1594/1594 [==============================] - 0s 132us/step - loss: 0.5162 - acc: 0.7867 - val_loss: 0.5108 - val_acc: 0.7915\n",
      "Epoch 75/100\n",
      "1594/1594 [==============================] - 0s 151us/step - loss: 0.5162 - acc: 0.7867 - val_loss: 0.5108 - val_acc: 0.7915\n",
      "Epoch 76/100\n",
      "1594/1594 [==============================] - 0s 142us/step - loss: 0.5161 - acc: 0.7867 - val_loss: 0.5108 - val_acc: 0.7915\n",
      "Epoch 77/100\n",
      "1594/1594 [==============================] - 0s 122us/step - loss: 0.5161 - acc: 0.7867 - val_loss: 0.5108 - val_acc: 0.7915\n",
      "Epoch 78/100\n",
      "1594/1594 [==============================] - 0s 128us/step - loss: 0.5161 - acc: 0.7867 - val_loss: 0.5108 - val_acc: 0.7915\n",
      "Epoch 79/100\n",
      "1594/1594 [==============================] - 0s 123us/step - loss: 0.5161 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 80/100\n",
      "1594/1594 [==============================] - 0s 123us/step - loss: 0.5160 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 81/100\n",
      "1594/1594 [==============================] - 0s 120us/step - loss: 0.5160 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 82/100\n",
      "1594/1594 [==============================] - 0s 119us/step - loss: 0.5160 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 83/100\n",
      "1594/1594 [==============================] - 0s 122us/step - loss: 0.5159 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 84/100\n",
      "1594/1594 [==============================] - 0s 134us/step - loss: 0.5159 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 85/100\n",
      "1594/1594 [==============================] - 0s 129us/step - loss: 0.5159 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 86/100\n",
      "1594/1594 [==============================] - 0s 132us/step - loss: 0.5158 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 87/100\n",
      "1594/1594 [==============================] - 0s 143us/step - loss: 0.5158 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 88/100\n",
      "1594/1594 [==============================] - 0s 120us/step - loss: 0.5158 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 89/100\n",
      "1594/1594 [==============================] - 0s 120us/step - loss: 0.5158 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 90/100\n",
      "1594/1594 [==============================] - 0s 130us/step - loss: 0.5157 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 91/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5157 - acc: 0.7867 - val_loss: 0.5105 - val_acc: 0.7915\n",
      "Epoch 92/100\n",
      "1594/1594 [==============================] - 0s 130us/step - loss: 0.5157 - acc: 0.7867 - val_loss: 0.5105 - val_acc: 0.7915\n",
      "Epoch 93/100\n",
      "1594/1594 [==============================] - 0s 128us/step - loss: 0.5156 - acc: 0.7867 - val_loss: 0.5105 - val_acc: 0.7915\n",
      "Epoch 94/100\n",
      "1594/1594 [==============================] - 0s 120us/step - loss: 0.5156 - acc: 0.7867 - val_loss: 0.5105 - val_acc: 0.7915\n",
      "Epoch 95/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5156 - acc: 0.7867 - val_loss: 0.5105 - val_acc: 0.7915\n",
      "Epoch 96/100\n",
      "1594/1594 [==============================] - 0s 138us/step - loss: 0.5156 - acc: 0.7867 - val_loss: 0.5105 - val_acc: 0.7915\n",
      "Epoch 97/100\n",
      "1594/1594 [==============================] - 0s 133us/step - loss: 0.5156 - acc: 0.7867 - val_loss: 0.5105 - val_acc: 0.7915\n",
      "Epoch 98/100\n",
      "1594/1594 [==============================] - 0s 150us/step - loss: 0.5155 - acc: 0.7867 - val_loss: 0.5105 - val_acc: 0.7915\n",
      "Epoch 99/100\n",
      "1594/1594 [==============================] - 0s 120us/step - loss: 0.5155 - acc: 0.7867 - val_loss: 0.5105 - val_acc: 0.7915\n",
      "Epoch 100/100\n",
      "1594/1594 [==============================] - 0s 132us/step - loss: 0.5155 - acc: 0.7867 - val_loss: 0.5105 - val_acc: 0.7915\n",
      "499/499 [==============================] - 0s 56us/step\n",
      "Test score: 0.5442695291582234\n",
      "Test accuracy: 0.7655310672605204\n"
     ]
    }
   ],
   "source": [
    "# Fit model A\n",
    "hista = fit_model(modela, x_train, y_train, \\\n",
    "                          x_val, y_val, \\\n",
    "                          x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:39.792586Z",
     "start_time": "2020-10-19T16:21:28.349199Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nfSYWYRkUy7h",
    "outputId": "01a173dd-b567-4958-a9a5-8a209e892f88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1594 samples, validate on 398 samples\n",
      "Epoch 1/100\n",
      "1594/1594 [==============================] - 1s 576us/step - loss: 0.6855 - acc: 0.7089 - val_loss: 0.6778 - val_acc: 0.7915\n",
      "Epoch 2/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 0.6710 - acc: 0.7867 - val_loss: 0.6635 - val_acc: 0.7915\n",
      "Epoch 3/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 0.6575 - acc: 0.7867 - val_loss: 0.6503 - val_acc: 0.7915\n",
      "Epoch 4/100\n",
      "1594/1594 [==============================] - 0s 105us/step - loss: 0.6448 - acc: 0.7867 - val_loss: 0.6377 - val_acc: 0.7915\n",
      "Epoch 5/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.6329 - acc: 0.7867 - val_loss: 0.6259 - val_acc: 0.7915\n",
      "Epoch 6/100\n",
      "1594/1594 [==============================] - 0s 92us/step - loss: 0.6217 - acc: 0.7867 - val_loss: 0.6150 - val_acc: 0.7915\n",
      "Epoch 7/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 0.6114 - acc: 0.7867 - val_loss: 0.6050 - val_acc: 0.7915\n",
      "Epoch 8/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.6019 - acc: 0.7867 - val_loss: 0.5955 - val_acc: 0.7915\n",
      "Epoch 9/100\n",
      "1594/1594 [==============================] - 0s 107us/step - loss: 0.5931 - acc: 0.7867 - val_loss: 0.5868 - val_acc: 0.7915\n",
      "Epoch 10/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.5849 - acc: 0.7867 - val_loss: 0.5790 - val_acc: 0.7915\n",
      "Epoch 11/100\n",
      "1594/1594 [==============================] - 0s 86us/step - loss: 0.5776 - acc: 0.7867 - val_loss: 0.5719 - val_acc: 0.7915\n",
      "Epoch 12/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 0.5711 - acc: 0.7867 - val_loss: 0.5656 - val_acc: 0.7915\n",
      "Epoch 13/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 0.5652 - acc: 0.7867 - val_loss: 0.5601 - val_acc: 0.7915\n",
      "Epoch 14/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 0.5601 - acc: 0.7867 - val_loss: 0.5550 - val_acc: 0.7915\n",
      "Epoch 15/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 0.5554 - acc: 0.7867 - val_loss: 0.5504 - val_acc: 0.7915\n",
      "Epoch 16/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 0.5512 - acc: 0.7867 - val_loss: 0.5462 - val_acc: 0.7915\n",
      "Epoch 17/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 0.5474 - acc: 0.7867 - val_loss: 0.5425 - val_acc: 0.7915\n",
      "Epoch 18/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 0.5440 - acc: 0.7867 - val_loss: 0.5393 - val_acc: 0.7915\n",
      "Epoch 19/100\n",
      "1594/1594 [==============================] - 0s 87us/step - loss: 0.5410 - acc: 0.7867 - val_loss: 0.5364 - val_acc: 0.7915\n",
      "Epoch 20/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 0.5384 - acc: 0.7867 - val_loss: 0.5337 - val_acc: 0.7915\n",
      "Epoch 21/100\n",
      "1594/1594 [==============================] - 0s 116us/step - loss: 0.5360 - acc: 0.7867 - val_loss: 0.5315 - val_acc: 0.7915\n",
      "Epoch 22/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.5340 - acc: 0.7867 - val_loss: 0.5294 - val_acc: 0.7915\n",
      "Epoch 23/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 0.5321 - acc: 0.7867 - val_loss: 0.5276 - val_acc: 0.7915\n",
      "Epoch 24/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.5304 - acc: 0.7867 - val_loss: 0.5258 - val_acc: 0.7915\n",
      "Epoch 25/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 0.5289 - acc: 0.7867 - val_loss: 0.5244 - val_acc: 0.7915\n",
      "Epoch 26/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 0.5276 - acc: 0.7867 - val_loss: 0.5231 - val_acc: 0.7915\n",
      "Epoch 27/100\n",
      "1594/1594 [==============================] - 0s 114us/step - loss: 0.5264 - acc: 0.7867 - val_loss: 0.5219 - val_acc: 0.7915\n",
      "Epoch 28/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 0.5254 - acc: 0.7867 - val_loss: 0.5208 - val_acc: 0.7915\n",
      "Epoch 29/100\n",
      "1594/1594 [==============================] - 0s 92us/step - loss: 0.5244 - acc: 0.7867 - val_loss: 0.5198 - val_acc: 0.7915\n",
      "Epoch 30/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.5235 - acc: 0.7867 - val_loss: 0.5190 - val_acc: 0.7915\n",
      "Epoch 31/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 0.5228 - acc: 0.7867 - val_loss: 0.5182 - val_acc: 0.7915\n",
      "Epoch 32/100\n",
      "1594/1594 [==============================] - 0s 95us/step - loss: 0.5221 - acc: 0.7867 - val_loss: 0.5175 - val_acc: 0.7915\n",
      "Epoch 33/100\n",
      "1594/1594 [==============================] - 0s 95us/step - loss: 0.5215 - acc: 0.7867 - val_loss: 0.5169 - val_acc: 0.7915\n",
      "Epoch 34/100\n",
      "1594/1594 [==============================] - 0s 105us/step - loss: 0.5209 - acc: 0.7867 - val_loss: 0.5163 - val_acc: 0.7915\n",
      "Epoch 35/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.5205 - acc: 0.7867 - val_loss: 0.5158 - val_acc: 0.7915\n",
      "Epoch 36/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 0.5200 - acc: 0.7867 - val_loss: 0.5154 - val_acc: 0.7915\n",
      "Epoch 37/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 0.5197 - acc: 0.7867 - val_loss: 0.5150 - val_acc: 0.7915\n",
      "Epoch 38/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.5193 - acc: 0.7867 - val_loss: 0.5147 - val_acc: 0.7915\n",
      "Epoch 39/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 0.5190 - acc: 0.7867 - val_loss: 0.5143 - val_acc: 0.7915\n",
      "Epoch 40/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 0.5187 - acc: 0.7867 - val_loss: 0.5141 - val_acc: 0.7915\n",
      "Epoch 41/100\n",
      "1594/1594 [==============================] - 0s 84us/step - loss: 0.5185 - acc: 0.7867 - val_loss: 0.5139 - val_acc: 0.7915\n",
      "Epoch 42/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 0.5183 - acc: 0.7867 - val_loss: 0.5137 - val_acc: 0.7915\n",
      "Epoch 43/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 0.5182 - acc: 0.7867 - val_loss: 0.5135 - val_acc: 0.7915\n",
      "Epoch 44/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 0.5180 - acc: 0.7867 - val_loss: 0.5133 - val_acc: 0.7915\n",
      "Epoch 45/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 0.5178 - acc: 0.7867 - val_loss: 0.5131 - val_acc: 0.7915\n",
      "Epoch 46/100\n",
      "1594/1594 [==============================] - 0s 111us/step - loss: 0.5177 - acc: 0.7867 - val_loss: 0.5130 - val_acc: 0.7915\n",
      "Epoch 47/100\n",
      "1594/1594 [==============================] - 0s 105us/step - loss: 0.5175 - acc: 0.7867 - val_loss: 0.5128 - val_acc: 0.7915\n",
      "Epoch 48/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 0.5174 - acc: 0.7867 - val_loss: 0.5127 - val_acc: 0.7915\n",
      "Epoch 49/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 0.5173 - acc: 0.7867 - val_loss: 0.5126 - val_acc: 0.7915\n",
      "Epoch 50/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 0.5172 - acc: 0.7867 - val_loss: 0.5125 - val_acc: 0.7915\n",
      "Epoch 51/100\n",
      "1594/1594 [==============================] - 0s 90us/step - loss: 0.5171 - acc: 0.7867 - val_loss: 0.5124 - val_acc: 0.7915\n",
      "Epoch 52/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 0.5170 - acc: 0.7867 - val_loss: 0.5123 - val_acc: 0.7915\n",
      "Epoch 53/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.5169 - acc: 0.7867 - val_loss: 0.5122 - val_acc: 0.7915\n",
      "Epoch 54/100\n",
      "1594/1594 [==============================] - 0s 113us/step - loss: 0.5169 - acc: 0.7867 - val_loss: 0.5122 - val_acc: 0.7915\n",
      "Epoch 55/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.5168 - acc: 0.7867 - val_loss: 0.5121 - val_acc: 0.7915\n",
      "Epoch 56/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 0.5167 - acc: 0.7867 - val_loss: 0.5120 - val_acc: 0.7915\n",
      "Epoch 57/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 0.5167 - acc: 0.7867 - val_loss: 0.5120 - val_acc: 0.7915\n",
      "Epoch 58/100\n",
      "1594/1594 [==============================] - 0s 115us/step - loss: 0.5166 - acc: 0.7867 - val_loss: 0.5120 - val_acc: 0.7915\n",
      "Epoch 59/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.5166 - acc: 0.7867 - val_loss: 0.5119 - val_acc: 0.7915\n",
      "Epoch 60/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 0.5165 - acc: 0.7867 - val_loss: 0.5119 - val_acc: 0.7915\n",
      "Epoch 61/100\n",
      "1594/1594 [==============================] - 0s 123us/step - loss: 0.5165 - acc: 0.7867 - val_loss: 0.5118 - val_acc: 0.7915\n",
      "Epoch 62/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.5164 - acc: 0.7867 - val_loss: 0.5118 - val_acc: 0.7915\n",
      "Epoch 63/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 0.5164 - acc: 0.7867 - val_loss: 0.5118 - val_acc: 0.7915\n",
      "Epoch 64/100\n",
      "1594/1594 [==============================] - 0s 108us/step - loss: 0.5163 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 65/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 0.5163 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 66/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.5163 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 67/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 0.5162 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 68/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 0.5162 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 69/100\n",
      "1594/1594 [==============================] - 0s 85us/step - loss: 0.5162 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 70/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 0.5161 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 71/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 0.5161 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 72/100\n",
      "1594/1594 [==============================] - 0s 84us/step - loss: 0.5161 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 73/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 0.5160 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 74/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 0.5160 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 75/100\n",
      "1594/1594 [==============================] - 0s 86us/step - loss: 0.5160 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 76/100\n",
      "1594/1594 [==============================] - 0s 85us/step - loss: 0.5159 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 77/100\n",
      "1594/1594 [==============================] - 0s 90us/step - loss: 0.5159 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 78/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.5159 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 79/100\n",
      "1594/1594 [==============================] - 0s 84us/step - loss: 0.5159 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 80/100\n",
      "1594/1594 [==============================] - 0s 90us/step - loss: 0.5158 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "Epoch 81/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 0.5158 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "Epoch 82/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 0.5158 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "Epoch 83/100\n",
      "1594/1594 [==============================] - 0s 86us/step - loss: 0.5157 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "Epoch 84/100\n",
      "1594/1594 [==============================] - 0s 88us/step - loss: 0.5157 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "Epoch 85/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.5157 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "Epoch 86/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 0.5156 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "Epoch 87/100\n",
      "1594/1594 [==============================] - 0s 119us/step - loss: 0.5156 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "Epoch 88/100\n",
      "1594/1594 [==============================] - 0s 113us/step - loss: 0.5156 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 89/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 0.5156 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 90/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 0.5155 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 91/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 0.5155 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 92/100\n",
      "1594/1594 [==============================] - 0s 84us/step - loss: 0.5155 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 93/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.5154 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 94/100\n",
      "1594/1594 [==============================] - 0s 95us/step - loss: 0.5154 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 95/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.5154 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 96/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 0.5153 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 97/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 0.5153 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "Epoch 98/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.5153 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "Epoch 99/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.5153 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "Epoch 100/100\n",
      "1594/1594 [==============================] - 0s 120us/step - loss: 0.5152 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "499/499 [==============================] - 0s 60us/step\n",
      "Test score: 0.5438855202021246\n",
      "Test accuracy: 0.7655310672605204\n"
     ]
    }
   ],
   "source": [
    "# Fit Model B\n",
    "histb = fit_model(modelb, x_train, y_train, \\\n",
    "                          x_val, y_val, \\\n",
    "                          x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:51.259794Z",
     "start_time": "2020-10-19T16:21:39.794586Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Aja5zAnUy7l",
    "outputId": "ce76d8fa-5338-4742-8898-0b344ee32f30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1594 samples, validate on 398 samples\n",
      "Epoch 1/100\n",
      "1594/1594 [==============================] - 1s 593us/step - loss: 0.6783 - acc: 0.7811 - val_loss: 0.6672 - val_acc: 0.7915\n",
      "Epoch 2/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.6574 - acc: 0.7867 - val_loss: 0.6448 - val_acc: 0.7915\n",
      "Epoch 3/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 0.6356 - acc: 0.7867 - val_loss: 0.6234 - val_acc: 0.7915\n",
      "Epoch 4/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 0.6156 - acc: 0.7867 - val_loss: 0.6042 - val_acc: 0.7915\n",
      "Epoch 5/100\n",
      "1594/1594 [==============================] - 0s 84us/step - loss: 0.5980 - acc: 0.7867 - val_loss: 0.5874 - val_acc: 0.7915\n",
      "Epoch 6/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 0.5830 - acc: 0.7867 - val_loss: 0.5740 - val_acc: 0.7915\n",
      "Epoch 7/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 0.5710 - acc: 0.7867 - val_loss: 0.5623 - val_acc: 0.7915\n",
      "Epoch 8/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 0.5605 - acc: 0.7867 - val_loss: 0.5529 - val_acc: 0.7915\n",
      "Epoch 9/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 0.5523 - acc: 0.7867 - val_loss: 0.5452 - val_acc: 0.7915\n",
      "Epoch 10/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 0.5456 - acc: 0.7867 - val_loss: 0.5393 - val_acc: 0.7915\n",
      "Epoch 11/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 0.5404 - acc: 0.7867 - val_loss: 0.5341 - val_acc: 0.7915\n",
      "Epoch 12/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 0.5358 - acc: 0.7867 - val_loss: 0.5298 - val_acc: 0.7915\n",
      "Epoch 13/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 0.5321 - acc: 0.7867 - val_loss: 0.5262 - val_acc: 0.7915\n",
      "Epoch 14/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.5290 - acc: 0.7867 - val_loss: 0.5235 - val_acc: 0.7915\n",
      "Epoch 15/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.5268 - acc: 0.7867 - val_loss: 0.5214 - val_acc: 0.7915\n",
      "Epoch 16/100\n",
      "1594/1594 [==============================] - 0s 90us/step - loss: 0.5250 - acc: 0.7867 - val_loss: 0.5196 - val_acc: 0.7915\n",
      "Epoch 17/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 0.5235 - acc: 0.7867 - val_loss: 0.5182 - val_acc: 0.7915\n",
      "Epoch 18/100\n",
      "1594/1594 [==============================] - 0s 86us/step - loss: 0.5223 - acc: 0.7867 - val_loss: 0.5169 - val_acc: 0.7915\n",
      "Epoch 19/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 0.5213 - acc: 0.7867 - val_loss: 0.5160 - val_acc: 0.7915\n",
      "Epoch 20/100\n",
      "1594/1594 [==============================] - 0s 90us/step - loss: 0.5205 - acc: 0.7867 - val_loss: 0.5151 - val_acc: 0.7915\n",
      "Epoch 21/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 0.5198 - acc: 0.7867 - val_loss: 0.5145 - val_acc: 0.7915\n",
      "Epoch 22/100\n",
      "1594/1594 [==============================] - 0s 111us/step - loss: 0.5192 - acc: 0.7867 - val_loss: 0.5139 - val_acc: 0.7915\n",
      "Epoch 23/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 0.5188 - acc: 0.7867 - val_loss: 0.5135 - val_acc: 0.7915\n",
      "Epoch 24/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 0.5185 - acc: 0.7867 - val_loss: 0.5131 - val_acc: 0.7915\n",
      "Epoch 25/100\n",
      "1594/1594 [==============================] - 0s 86us/step - loss: 0.5182 - acc: 0.7867 - val_loss: 0.5128 - val_acc: 0.7915\n",
      "Epoch 26/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 0.5180 - acc: 0.7867 - val_loss: 0.5126 - val_acc: 0.7915\n",
      "Epoch 27/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 0.5178 - acc: 0.7867 - val_loss: 0.5124 - val_acc: 0.7915\n",
      "Epoch 28/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 0.5176 - acc: 0.7867 - val_loss: 0.5122 - val_acc: 0.7915\n",
      "Epoch 29/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.5175 - acc: 0.7867 - val_loss: 0.5121 - val_acc: 0.7915\n",
      "Epoch 30/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 0.5173 - acc: 0.7867 - val_loss: 0.5120 - val_acc: 0.7915\n",
      "Epoch 31/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 0.5173 - acc: 0.7867 - val_loss: 0.5119 - val_acc: 0.7915\n",
      "Epoch 32/100\n",
      "1594/1594 [==============================] - 0s 95us/step - loss: 0.5172 - acc: 0.7867 - val_loss: 0.5118 - val_acc: 0.7915\n",
      "Epoch 33/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 0.5171 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 34/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 0.5170 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 35/100\n",
      "1594/1594 [==============================] - ETA: 0s - loss: 0.5238 - acc: 0.781 - 0s 100us/step - loss: 0.5169 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 36/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.5169 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 37/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.5168 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 38/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.5167 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 39/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 0.5167 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "Epoch 40/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.5167 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "Epoch 41/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 0.5166 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "Epoch 42/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 0.5166 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 43/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.5165 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 44/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 0.5165 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 45/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.5164 - acc: 0.7867 - val_loss: 0.5113 - val_acc: 0.7915\n",
      "Epoch 46/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.5164 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "Epoch 47/100\n",
      "1594/1594 [==============================] - 0s 110us/step - loss: 0.5163 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "Epoch 48/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.5163 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "Epoch 49/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.5162 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "Epoch 50/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 0.5162 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "Epoch 51/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 0.5162 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "Epoch 52/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 0.5161 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "Epoch 53/100\n",
      "1594/1594 [==============================] - 0s 108us/step - loss: 0.5161 - acc: 0.7867 - val_loss: 0.5112 - val_acc: 0.7915\n",
      "Epoch 54/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 0.5160 - acc: 0.7867 - val_loss: 0.5111 - val_acc: 0.7915\n",
      "Epoch 55/100\n",
      "1594/1594 [==============================] - 0s 112us/step - loss: 0.5160 - acc: 0.7867 - val_loss: 0.5111 - val_acc: 0.7915\n",
      "Epoch 56/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 0.5160 - acc: 0.7867 - val_loss: 0.5111 - val_acc: 0.7915\n",
      "Epoch 57/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 0.5159 - acc: 0.7867 - val_loss: 0.5111 - val_acc: 0.7915\n",
      "Epoch 58/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 0.5159 - acc: 0.7867 - val_loss: 0.5111 - val_acc: 0.7915\n",
      "Epoch 59/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.5159 - acc: 0.7867 - val_loss: 0.5111 - val_acc: 0.7915\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594/1594 [==============================] - 0s 97us/step - loss: 0.5158 - acc: 0.7867 - val_loss: 0.5111 - val_acc: 0.7915\n",
      "Epoch 61/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 0.5158 - acc: 0.7867 - val_loss: 0.5111 - val_acc: 0.7915\n",
      "Epoch 62/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 0.5157 - acc: 0.7867 - val_loss: 0.5110 - val_acc: 0.7915\n",
      "Epoch 63/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.5157 - acc: 0.7867 - val_loss: 0.5110 - val_acc: 0.7915\n",
      "Epoch 64/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 0.5156 - acc: 0.7867 - val_loss: 0.5110 - val_acc: 0.7915\n",
      "Epoch 65/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.5156 - acc: 0.7867 - val_loss: 0.5110 - val_acc: 0.7915\n",
      "Epoch 66/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 0.5156 - acc: 0.7867 - val_loss: 0.5110 - val_acc: 0.7915\n",
      "Epoch 67/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.5155 - acc: 0.7867 - val_loss: 0.5110 - val_acc: 0.7915\n",
      "Epoch 68/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 0.5155 - acc: 0.7867 - val_loss: 0.5110 - val_acc: 0.7915\n",
      "Epoch 69/100\n",
      "1594/1594 [==============================] - 0s 105us/step - loss: 0.5154 - acc: 0.7867 - val_loss: 0.5109 - val_acc: 0.7915\n",
      "Epoch 70/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 0.5154 - acc: 0.7867 - val_loss: 0.5109 - val_acc: 0.7915\n",
      "Epoch 71/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 0.5154 - acc: 0.7867 - val_loss: 0.5109 - val_acc: 0.7915\n",
      "Epoch 72/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 0.5153 - acc: 0.7867 - val_loss: 0.5109 - val_acc: 0.7915\n",
      "Epoch 73/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 0.5153 - acc: 0.7867 - val_loss: 0.5109 - val_acc: 0.7915\n",
      "Epoch 74/100\n",
      "1594/1594 [==============================] - 0s 108us/step - loss: 0.5152 - acc: 0.7867 - val_loss: 0.5109 - val_acc: 0.7915\n",
      "Epoch 75/100\n",
      "1594/1594 [==============================] - 0s 107us/step - loss: 0.5152 - acc: 0.7867 - val_loss: 0.5108 - val_acc: 0.7915\n",
      "Epoch 76/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.5151 - acc: 0.7867 - val_loss: 0.5108 - val_acc: 0.7915\n",
      "Epoch 77/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 0.5151 - acc: 0.7867 - val_loss: 0.5108 - val_acc: 0.7915\n",
      "Epoch 78/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.5151 - acc: 0.7867 - val_loss: 0.5108 - val_acc: 0.7915\n",
      "Epoch 79/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 0.5150 - acc: 0.7867 - val_loss: 0.5108 - val_acc: 0.7915\n",
      "Epoch 80/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 0.5150 - acc: 0.7867 - val_loss: 0.5108 - val_acc: 0.7915\n",
      "Epoch 81/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.5149 - acc: 0.7867 - val_loss: 0.5108 - val_acc: 0.7915\n",
      "Epoch 82/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 0.5149 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 83/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.5148 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 84/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 0.5148 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 85/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 0.5148 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 86/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 0.5147 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 87/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 0.5147 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 88/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.5146 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 89/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 0.5146 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 90/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 0.5146 - acc: 0.7867 - val_loss: 0.5107 - val_acc: 0.7915\n",
      "Epoch 91/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.5145 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 92/100\n",
      "1594/1594 [==============================] - 0s 105us/step - loss: 0.5145 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 93/100\n",
      "1594/1594 [==============================] - 0s 95us/step - loss: 0.5144 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 94/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.5144 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 95/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.5143 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 96/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 0.5143 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 97/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.5142 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 98/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 0.5142 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 99/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 0.5141 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "Epoch 100/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 0.5141 - acc: 0.7867 - val_loss: 0.5106 - val_acc: 0.7915\n",
      "499/499 [==============================] - 0s 50us/step\n",
      "Test score: 0.5446850127113129\n",
      "Test accuracy: 0.7655310672605204\n"
     ]
    }
   ],
   "source": [
    "# Fit Model C\n",
    "histc = fit_model(modelc, x_train, y_train, \\\n",
    "                          x_val, y_val, \\\n",
    "                          x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:51.265793Z",
     "start_time": "2020-10-19T16:21:51.261793Z"
    },
    "collapsed": true,
    "id": "TJ_-stQYUy7n"
   },
   "outputs": [],
   "source": [
    "# Use exponential decay to smooth performance curve (optional)\n",
    "\n",
    "\n",
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:51.419112Z",
     "start_time": "2020-10-19T16:21:51.268093Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "l7RxoZZpUy7q",
    "outputId": "054557b9-f79c-4be3-cb53-db0eb1872955"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27f02b6a6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot validation loss curves\n",
    "\n",
    "\n",
    "# add your code here\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#epochs=list(range(0,10))\n",
    "epochs = range(1, len(hista.history['val_loss']) + 1)\n",
    "\n",
    "val_loss_a = hista.history['val_loss']\n",
    "val_loss_b = histb.history['val_loss']\n",
    "val_loss_c = histc.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, val_loss_a, 'r', label='Model A')\n",
    "plt.plot(epochs, val_loss_b, 'b', label='Model B')\n",
    "plt.plot(epochs, val_loss_c, 'g', label='Model C')\n",
    "\n",
    "plt.title('Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epochs)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:55.843609Z",
     "start_time": "2020-10-19T16:21:55.707669Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "ISUYVTZLUy7t",
    "outputId": "7790217a-a37d-494b-d46a-fdab3da7dc4c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27f02f16e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot validation accuracy curves\n",
    "epochs=list(range(0,100))\n",
    "\n",
    "# add your code here\n",
    "val_acc_a = hista.history['val_acc']\n",
    "val_acc_b = histb.history['val_acc']\n",
    "val_acc_c = histc.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, val_acc_a, 'r', label='Model A')\n",
    "plt.plot(epochs, val_acc_b, 'b', label='Model B')\n",
    "plt.plot(epochs, val_acc_c, 'g', label='Model C')\n",
    "\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(epochs)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis\n",
    "\n",
    "1.For each model, from which epoch, overfitting started happening?\n",
    "- From my results, I don't find overfitting situation.\n",
    "\n",
    "2.Which model in general performs the best in terms of valiation loss or validation accuracy?\n",
    "- For three medels, I find that the validation accuracies are the same. Maybe the Model C will have best performance because of the validation loss value.\n",
    "\n",
    "3.Please explain why this model outperforms the others\n",
    "- Maybe ModelC have two hidden layers.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzcyVVMzUy7v"
   },
   "source": [
    "### Task 3: Fight overfitting \n",
    "- Let's take **Model B** and try the following strategies to overcome overfitting\n",
    "    1. Model B1 (**Dropout**): Add a `Dropout` layer with dropout rate 0.5 to `after the input` (i.e. randomly drop 50% of the input; place it `before the the hidden layer`). Then add another `Dropout` layer with dropout rate 0.5 `after the hidden layer`\n",
    "    2. Model B2 (**L2 Regularizer**): Add L2 kernel regularization with a coefficient of 0.001 in the hidden layer.\n",
    "- Train each model as in Task 2 \n",
    "- Plot validation loss and validation accuracy vs. epoches from the training histories of these <font color=red>three</font> models: B, B1, B2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:58.399945Z",
     "start_time": "2020-10-19T16:21:58.395951Z"
    },
    "collapsed": true,
    "id": "Cqi6U4aeUy7w"
   },
   "outputs": [],
   "source": [
    "# Define Model B1\n",
    "from keras.layers import Dropout\n",
    "# add your code here\n",
    "modelb1 = Sequential()\n",
    "modelb1.add(Dropout(0.5, input_shape=(4402,)))\n",
    "modelb1.add(Dense(units=128, activation='relu'))   \n",
    "modelb1.add(Dropout(0.5))\n",
    "modelb1.add(Dense(units=1, activation='sigmoid')) \n",
    "modelb1.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:59.820089Z",
     "start_time": "2020-10-19T16:21:59.796096Z"
    },
    "collapsed": true,
    "id": "ltjjhJIrUy7y"
   },
   "outputs": [],
   "source": [
    "# Define Model B2\n",
    "from keras import regularizers\n",
    "# add your code here\n",
    "modelb2 = Sequential()\n",
    "modelb2.add(Dense(units=128, activation='relu',input_dim = 4402,kernel_regularizer=regularizers.l2(0.001)))   \n",
    "modelb2.add(Dense(units=1, activation='sigmoid')) \n",
    "modelb2.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:21:09.945699Z",
     "start_time": "2020-10-19T16:21:09.707793Z"
    },
    "collapsed": true,
    "id": "f1USAEKOkFaz"
   },
   "outputs": [],
   "source": [
    "# Define Model B\n",
    "\n",
    "# add your code here\n",
    "modelb = Sequential()\n",
    "modelb.add(Dense(units=128, activation='relu',input_dim = 4402))   \n",
    "modelb.add(Dense(units=1, activation='sigmoid')) \n",
    "modelb.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "# Display model graph\n",
    "#G = model_to_dot (modelb)\n",
    "#Image (G.create (prog = \"dot\", format = \"png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:22:17.890016Z",
     "start_time": "2020-10-19T16:22:01.187942Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4KJPkWvgUy71",
    "outputId": "01038628-5c01-45d6-db70-28265b547111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1594 samples, validate on 398 samples\n",
      "Epoch 1/100\n",
      "1594/1594 [==============================] - 1s 745us/step - loss: 0.6810 - acc: 0.7102 - val_loss: 0.6740 - val_acc: 0.7915\n",
      "Epoch 2/100\n",
      "1594/1594 [==============================] - 0s 134us/step - loss: 0.6660 - acc: 0.7829 - val_loss: 0.6597 - val_acc: 0.7915\n",
      "Epoch 3/100\n",
      "1594/1594 [==============================] - 0s 143us/step - loss: 0.6528 - acc: 0.7867 - val_loss: 0.6461 - val_acc: 0.7915\n",
      "Epoch 4/100\n",
      "1594/1594 [==============================] - 0s 145us/step - loss: 0.6390 - acc: 0.7867 - val_loss: 0.6335 - val_acc: 0.7915\n",
      "Epoch 5/100\n",
      "1594/1594 [==============================] - 0s 130us/step - loss: 0.6287 - acc: 0.7867 - val_loss: 0.6215 - val_acc: 0.7915\n",
      "Epoch 6/100\n",
      "1594/1594 [==============================] - 0s 133us/step - loss: 0.6169 - acc: 0.7867 - val_loss: 0.6106 - val_acc: 0.7915\n",
      "Epoch 7/100\n",
      "1594/1594 [==============================] - 0s 133us/step - loss: 0.6076 - acc: 0.7867 - val_loss: 0.6005 - val_acc: 0.7915\n",
      "Epoch 8/100\n",
      "1594/1594 [==============================] - 0s 141us/step - loss: 0.5969 - acc: 0.7867 - val_loss: 0.5914 - val_acc: 0.7915\n",
      "Epoch 9/100\n",
      "1594/1594 [==============================] - 0s 134us/step - loss: 0.5883 - acc: 0.7867 - val_loss: 0.5827 - val_acc: 0.7915\n",
      "Epoch 10/100\n",
      "1594/1594 [==============================] - 0s 139us/step - loss: 0.5808 - acc: 0.7867 - val_loss: 0.5747 - val_acc: 0.7915\n",
      "Epoch 11/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5752 - acc: 0.7867 - val_loss: 0.5676 - val_acc: 0.7915\n",
      "Epoch 12/100\n",
      "1594/1594 [==============================] - 0s 142us/step - loss: 0.5676 - acc: 0.7867 - val_loss: 0.5614 - val_acc: 0.7915\n",
      "Epoch 13/100\n",
      "1594/1594 [==============================] - 0s 141us/step - loss: 0.5629 - acc: 0.7867 - val_loss: 0.5558 - val_acc: 0.7915\n",
      "Epoch 14/100\n",
      "1594/1594 [==============================] - 0s 140us/step - loss: 0.5573 - acc: 0.7867 - val_loss: 0.5507 - val_acc: 0.7915\n",
      "Epoch 15/100\n",
      "1594/1594 [==============================] - 0s 136us/step - loss: 0.5541 - acc: 0.7867 - val_loss: 0.5463 - val_acc: 0.7915\n",
      "Epoch 16/100\n",
      "1594/1594 [==============================] - 0s 146us/step - loss: 0.5489 - acc: 0.7867 - val_loss: 0.5424 - val_acc: 0.7915\n",
      "Epoch 17/100\n",
      "1594/1594 [==============================] - 0s 143us/step - loss: 0.5462 - acc: 0.7867 - val_loss: 0.5389 - val_acc: 0.7915\n",
      "Epoch 18/100\n",
      "1594/1594 [==============================] - 0s 133us/step - loss: 0.5424 - acc: 0.7867 - val_loss: 0.5358 - val_acc: 0.7915\n",
      "Epoch 19/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5383 - acc: 0.7867 - val_loss: 0.5328 - val_acc: 0.7915\n",
      "Epoch 20/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5356 - acc: 0.7867 - val_loss: 0.5304 - val_acc: 0.7915\n",
      "Epoch 21/100\n",
      "1594/1594 [==============================] - 0s 155us/step - loss: 0.5343 - acc: 0.7867 - val_loss: 0.5282 - val_acc: 0.7915\n",
      "Epoch 22/100\n",
      "1594/1594 [==============================] - 0s 165us/step - loss: 0.5325 - acc: 0.7867 - val_loss: 0.5264 - val_acc: 0.7915\n",
      "Epoch 23/100\n",
      "1594/1594 [==============================] - 0s 130us/step - loss: 0.5312 - acc: 0.7867 - val_loss: 0.5248 - val_acc: 0.7915\n",
      "Epoch 24/100\n",
      "1594/1594 [==============================] - 0s 143us/step - loss: 0.5303 - acc: 0.7867 - val_loss: 0.5234 - val_acc: 0.7915\n",
      "Epoch 25/100\n",
      "1594/1594 [==============================] - 0s 138us/step - loss: 0.5280 - acc: 0.7867 - val_loss: 0.5221 - val_acc: 0.7915\n",
      "Epoch 26/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5258 - acc: 0.7867 - val_loss: 0.5210 - val_acc: 0.7915\n",
      "Epoch 27/100\n",
      "1594/1594 [==============================] - 0s 135us/step - loss: 0.5254 - acc: 0.7867 - val_loss: 0.5199 - val_acc: 0.7915\n",
      "Epoch 28/100\n",
      "1594/1594 [==============================] - 0s 138us/step - loss: 0.5239 - acc: 0.7867 - val_loss: 0.5191 - val_acc: 0.7915\n",
      "Epoch 29/100\n",
      "1594/1594 [==============================] - 0s 128us/step - loss: 0.5257 - acc: 0.7867 - val_loss: 0.5184 - val_acc: 0.7915\n",
      "Epoch 30/100\n",
      "1594/1594 [==============================] - 0s 133us/step - loss: 0.5231 - acc: 0.7867 - val_loss: 0.5177 - val_acc: 0.7915\n",
      "Epoch 31/100\n",
      "1594/1594 [==============================] - 0s 142us/step - loss: 0.5238 - acc: 0.7867 - val_loss: 0.5170 - val_acc: 0.7915\n",
      "Epoch 32/100\n",
      "1594/1594 [==============================] - 0s 133us/step - loss: 0.5234 - acc: 0.7867 - val_loss: 0.5165 - val_acc: 0.7915\n",
      "Epoch 33/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5227 - acc: 0.7867 - val_loss: 0.5161 - val_acc: 0.7915\n",
      "Epoch 34/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5212 - acc: 0.7867 - val_loss: 0.5156 - val_acc: 0.7915\n",
      "Epoch 35/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5215 - acc: 0.7867 - val_loss: 0.5152 - val_acc: 0.7915\n",
      "Epoch 36/100\n",
      "1594/1594 [==============================] - 0s 130us/step - loss: 0.5188 - acc: 0.7867 - val_loss: 0.5149 - val_acc: 0.7915\n",
      "Epoch 37/100\n",
      "1594/1594 [==============================] - 0s 134us/step - loss: 0.5222 - acc: 0.7867 - val_loss: 0.5145 - val_acc: 0.7915\n",
      "Epoch 38/100\n",
      "1594/1594 [==============================] - 0s 127us/step - loss: 0.5206 - acc: 0.7867 - val_loss: 0.5142 - val_acc: 0.7915\n",
      "Epoch 39/100\n",
      "1594/1594 [==============================] - 0s 132us/step - loss: 0.5200 - acc: 0.7867 - val_loss: 0.5140 - val_acc: 0.7915\n",
      "Epoch 40/100\n",
      "1594/1594 [==============================] - 0s 127us/step - loss: 0.5203 - acc: 0.7867 - val_loss: 0.5137 - val_acc: 0.7915\n",
      "Epoch 41/100\n",
      "1594/1594 [==============================] - 0s 147us/step - loss: 0.5231 - acc: 0.7867 - val_loss: 0.5136 - val_acc: 0.7915\n",
      "Epoch 42/100\n",
      "1594/1594 [==============================] - 0s 139us/step - loss: 0.5211 - acc: 0.7867 - val_loss: 0.5134 - val_acc: 0.7915\n",
      "Epoch 43/100\n",
      "1594/1594 [==============================] - 0s 129us/step - loss: 0.5188 - acc: 0.7867 - val_loss: 0.5132 - val_acc: 0.7915\n",
      "Epoch 44/100\n",
      "1594/1594 [==============================] - 0s 148us/step - loss: 0.5192 - acc: 0.7867 - val_loss: 0.5131 - val_acc: 0.7915\n",
      "Epoch 45/100\n",
      "1594/1594 [==============================] - 0s 136us/step - loss: 0.5192 - acc: 0.7867 - val_loss: 0.5130 - val_acc: 0.7915\n",
      "Epoch 46/100\n",
      "1594/1594 [==============================] - 0s 158us/step - loss: 0.5182 - acc: 0.7867 - val_loss: 0.5128 - val_acc: 0.7915\n",
      "Epoch 47/100\n",
      "1594/1594 [==============================] - 0s 149us/step - loss: 0.5178 - acc: 0.7867 - val_loss: 0.5127 - val_acc: 0.7915\n",
      "Epoch 48/100\n",
      "1594/1594 [==============================] - 0s 137us/step - loss: 0.5186 - acc: 0.7867 - val_loss: 0.5126 - val_acc: 0.7915\n",
      "Epoch 49/100\n",
      "1594/1594 [==============================] - 0s 135us/step - loss: 0.5169 - acc: 0.7867 - val_loss: 0.5125 - val_acc: 0.7915\n",
      "Epoch 50/100\n",
      "1594/1594 [==============================] - 0s 136us/step - loss: 0.5202 - acc: 0.7867 - val_loss: 0.5125 - val_acc: 0.7915\n",
      "Epoch 51/100\n",
      "1594/1594 [==============================] - 0s 140us/step - loss: 0.5188 - acc: 0.7867 - val_loss: 0.5124 - val_acc: 0.7915\n",
      "Epoch 52/100\n",
      "1594/1594 [==============================] - 0s 128us/step - loss: 0.5191 - acc: 0.7867 - val_loss: 0.5124 - val_acc: 0.7915\n",
      "Epoch 53/100\n",
      "1594/1594 [==============================] - 0s 133us/step - loss: 0.5180 - acc: 0.7867 - val_loss: 0.5123 - val_acc: 0.7915\n",
      "Epoch 54/100\n",
      "1594/1594 [==============================] - 0s 138us/step - loss: 0.5186 - acc: 0.7867 - val_loss: 0.5123 - val_acc: 0.7915\n",
      "Epoch 55/100\n",
      "1594/1594 [==============================] - 0s 155us/step - loss: 0.5210 - acc: 0.7867 - val_loss: 0.5122 - val_acc: 0.7915\n",
      "Epoch 56/100\n",
      "1594/1594 [==============================] - 0s 141us/step - loss: 0.5188 - acc: 0.7867 - val_loss: 0.5122 - val_acc: 0.7915\n",
      "Epoch 57/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5169 - acc: 0.7867 - val_loss: 0.5122 - val_acc: 0.7915\n",
      "Epoch 58/100\n",
      "1594/1594 [==============================] - 0s 144us/step - loss: 0.5195 - acc: 0.7867 - val_loss: 0.5121 - val_acc: 0.7915\n",
      "Epoch 59/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5172 - acc: 0.7867 - val_loss: 0.5121 - val_acc: 0.7915\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594/1594 [==============================] - 0s 144us/step - loss: 0.5188 - acc: 0.7867 - val_loss: 0.5121 - val_acc: 0.7915\n",
      "Epoch 61/100\n",
      "1594/1594 [==============================] - 0s 128us/step - loss: 0.5193 - acc: 0.7867 - val_loss: 0.5120 - val_acc: 0.7915\n",
      "Epoch 62/100\n",
      "1594/1594 [==============================] - 0s 137us/step - loss: 0.5190 - acc: 0.7867 - val_loss: 0.5120 - val_acc: 0.7915\n",
      "Epoch 63/100\n",
      "1594/1594 [==============================] - 0s 151us/step - loss: 0.5168 - acc: 0.7867 - val_loss: 0.5120 - val_acc: 0.7915\n",
      "Epoch 64/100\n",
      "1594/1594 [==============================] - 0s 156us/step - loss: 0.5176 - acc: 0.7867 - val_loss: 0.5120 - val_acc: 0.7915\n",
      "Epoch 65/100\n",
      "1594/1594 [==============================] - 0s 137us/step - loss: 0.5176 - acc: 0.7867 - val_loss: 0.5119 - val_acc: 0.7915\n",
      "Epoch 66/100\n",
      "1594/1594 [==============================] - 0s 154us/step - loss: 0.5174 - acc: 0.7867 - val_loss: 0.5119 - val_acc: 0.7915\n",
      "Epoch 67/100\n",
      "1594/1594 [==============================] - 0s 151us/step - loss: 0.5163 - acc: 0.7867 - val_loss: 0.5119 - val_acc: 0.7915\n",
      "Epoch 68/100\n",
      "1594/1594 [==============================] - 0s 161us/step - loss: 0.5182 - acc: 0.7867 - val_loss: 0.5119 - val_acc: 0.7915\n",
      "Epoch 69/100\n",
      "1594/1594 [==============================] - 0s 159us/step - loss: 0.5167 - acc: 0.7867 - val_loss: 0.5118 - val_acc: 0.7915\n",
      "Epoch 70/100\n",
      "1594/1594 [==============================] - 0s 153us/step - loss: 0.5173 - acc: 0.7867 - val_loss: 0.5118 - val_acc: 0.7915\n",
      "Epoch 71/100\n",
      "1594/1594 [==============================] - 0s 143us/step - loss: 0.5180 - acc: 0.7867 - val_loss: 0.5118 - val_acc: 0.7915\n",
      "Epoch 72/100\n",
      "1594/1594 [==============================] - 0s 129us/step - loss: 0.5183 - acc: 0.7867 - val_loss: 0.5118 - val_acc: 0.7915\n",
      "Epoch 73/100\n",
      "1594/1594 [==============================] - 0s 144us/step - loss: 0.5164 - acc: 0.7867 - val_loss: 0.5118 - val_acc: 0.7915\n",
      "Epoch 74/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.5150 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 75/100\n",
      "1594/1594 [==============================] - 0s 149us/step - loss: 0.5185 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 76/100\n",
      "1594/1594 [==============================] - 0s 143us/step - loss: 0.5160 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 77/100\n",
      "1594/1594 [==============================] - 0s 142us/step - loss: 0.5181 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 78/100\n",
      "1594/1594 [==============================] - 0s 144us/step - loss: 0.5158 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 79/100\n",
      "1594/1594 [==============================] - 0s 149us/step - loss: 0.5186 - acc: 0.7867 - val_loss: 0.5117 - val_acc: 0.7915\n",
      "Epoch 80/100\n",
      "1594/1594 [==============================] - 0s 142us/step - loss: 0.5177 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 81/100\n",
      "1594/1594 [==============================] - 0s 157us/step - loss: 0.5172 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 82/100\n",
      "1594/1594 [==============================] - 0s 145us/step - loss: 0.5171 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 83/100\n",
      "1594/1594 [==============================] - 0s 144us/step - loss: 0.5186 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 84/100\n",
      "1594/1594 [==============================] - 0s 151us/step - loss: 0.5178 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 85/100\n",
      "1594/1594 [==============================] - 0s 154us/step - loss: 0.5152 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 86/100\n",
      "1594/1594 [==============================] - 0s 138us/step - loss: 0.5184 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 87/100\n",
      "1594/1594 [==============================] - 0s 151us/step - loss: 0.5184 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 88/100\n",
      "1594/1594 [==============================] - 0s 149us/step - loss: 0.5168 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 89/100\n",
      "1594/1594 [==============================] - 0s 151us/step - loss: 0.5165 - acc: 0.7867 - val_loss: 0.5116 - val_acc: 0.7915\n",
      "Epoch 90/100\n",
      "1594/1594 [==============================] - 0s 150us/step - loss: 0.5161 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 91/100\n",
      "1594/1594 [==============================] - 0s 141us/step - loss: 0.5157 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 92/100\n",
      "1594/1594 [==============================] - 0s 137us/step - loss: 0.5172 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 93/100\n",
      "1594/1594 [==============================] - 0s 144us/step - loss: 0.5183 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 94/100\n",
      "1594/1594 [==============================] - 0s 152us/step - loss: 0.5174 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 95/100\n",
      "1594/1594 [==============================] - 0s 128us/step - loss: 0.5153 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 96/100\n",
      "1594/1594 [==============================] - 0s 146us/step - loss: 0.5184 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 97/100\n",
      "1594/1594 [==============================] - 0s 146us/step - loss: 0.5167 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 98/100\n",
      "1594/1594 [==============================] - 0s 151us/step - loss: 0.5163 - acc: 0.7867 - val_loss: 0.5115 - val_acc: 0.7915\n",
      "Epoch 99/100\n",
      "1594/1594 [==============================] - 0s 151us/step - loss: 0.5182 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "Epoch 100/100\n",
      "1594/1594 [==============================] - 0s 149us/step - loss: 0.5168 - acc: 0.7867 - val_loss: 0.5114 - val_acc: 0.7915\n",
      "499/499 [==============================] - 0s 58us/step\n",
      "Test score: 0.5458079491684098\n",
      "Test accuracy: 0.7655310672605204\n"
     ]
    }
   ],
   "source": [
    "# Fit Model B1\n",
    "histb1 = fit_model(modelb1, x_train, y_train, \\\n",
    "                          x_val, y_val, \\\n",
    "                          x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:22:30.956074Z",
     "start_time": "2020-10-19T16:22:17.892016Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMZL-iL1Uy75",
    "outputId": "3624a3bd-db1c-45b9-b05e-1e9d33896759"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1594 samples, validate on 398 samples\n",
      "Epoch 1/100\n",
      "1594/1594 [==============================] - 1s 743us/step - loss: 0.9318 - acc: 0.7503 - val_loss: 0.9235 - val_acc: 0.7915\n",
      "Epoch 2/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 0.9171 - acc: 0.7867 - val_loss: 0.9093 - val_acc: 0.7915\n",
      "Epoch 3/100\n",
      "1594/1594 [==============================] - 0s 134us/step - loss: 0.9035 - acc: 0.7867 - val_loss: 0.8957 - val_acc: 0.7915\n",
      "Epoch 4/100\n",
      "1594/1594 [==============================] - 0s 123us/step - loss: 0.8906 - acc: 0.7867 - val_loss: 0.8831 - val_acc: 0.7915\n",
      "Epoch 5/100\n",
      "1594/1594 [==============================] - 0s 124us/step - loss: 0.8786 - acc: 0.7867 - val_loss: 0.8713 - val_acc: 0.7915\n",
      "Epoch 6/100\n",
      "1594/1594 [==============================] - 0s 138us/step - loss: 0.8674 - acc: 0.7867 - val_loss: 0.8601 - val_acc: 0.7915\n",
      "Epoch 7/100\n",
      "1594/1594 [==============================] - 0s 122us/step - loss: 0.8569 - acc: 0.7867 - val_loss: 0.8498 - val_acc: 0.7915\n",
      "Epoch 8/100\n",
      "1594/1594 [==============================] - 0s 116us/step - loss: 0.8472 - acc: 0.7867 - val_loss: 0.8404 - val_acc: 0.7915\n",
      "Epoch 9/100\n",
      "1594/1594 [==============================] - 0s 108us/step - loss: 0.8384 - acc: 0.7867 - val_loss: 0.8318 - val_acc: 0.7915\n",
      "Epoch 10/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.8304 - acc: 0.7867 - val_loss: 0.8238 - val_acc: 0.7915\n",
      "Epoch 11/100\n",
      "1594/1594 [==============================] - 0s 108us/step - loss: 0.8230 - acc: 0.7867 - val_loss: 0.8167 - val_acc: 0.7915\n",
      "Epoch 12/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 0.8164 - acc: 0.7867 - val_loss: 0.8102 - val_acc: 0.7915\n",
      "Epoch 13/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.8105 - acc: 0.7867 - val_loss: 0.8045 - val_acc: 0.7915\n",
      "Epoch 14/100\n",
      "1594/1594 [==============================] - 0s 120us/step - loss: 0.8052 - acc: 0.7867 - val_loss: 0.7994 - val_acc: 0.7915\n",
      "Epoch 15/100\n",
      "1594/1594 [==============================] - 0s 107us/step - loss: 0.8005 - acc: 0.7867 - val_loss: 0.7947 - val_acc: 0.7915\n",
      "Epoch 16/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.7962 - acc: 0.7867 - val_loss: 0.7905 - val_acc: 0.7915\n",
      "Epoch 17/100\n",
      "1594/1594 [==============================] - 0s 107us/step - loss: 0.7923 - acc: 0.7867 - val_loss: 0.7868 - val_acc: 0.7915\n",
      "Epoch 18/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 0.7890 - acc: 0.7867 - val_loss: 0.7834 - val_acc: 0.7915\n",
      "Epoch 19/100\n",
      "1594/1594 [==============================] - 0s 116us/step - loss: 0.7859 - acc: 0.7867 - val_loss: 0.7805 - val_acc: 0.7915\n",
      "Epoch 20/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 0.7832 - acc: 0.7867 - val_loss: 0.7779 - val_acc: 0.7915\n",
      "Epoch 21/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.7809 - acc: 0.7867 - val_loss: 0.7756 - val_acc: 0.7915\n",
      "Epoch 22/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.7788 - acc: 0.7867 - val_loss: 0.7734 - val_acc: 0.7915\n",
      "Epoch 23/100\n",
      "1594/1594 [==============================] - 0s 105us/step - loss: 0.7768 - acc: 0.7867 - val_loss: 0.7715 - val_acc: 0.7915\n",
      "Epoch 24/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.7751 - acc: 0.7867 - val_loss: 0.7698 - val_acc: 0.7915\n",
      "Epoch 25/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.7735 - acc: 0.7867 - val_loss: 0.7682 - val_acc: 0.7915\n",
      "Epoch 26/100\n",
      "1594/1594 [==============================] - 0s 149us/step - loss: 0.7721 - acc: 0.7867 - val_loss: 0.7668 - val_acc: 0.7915\n",
      "Epoch 27/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 0.7708 - acc: 0.7867 - val_loss: 0.7656 - val_acc: 0.7915\n",
      "Epoch 28/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 0.7697 - acc: 0.7867 - val_loss: 0.7644 - val_acc: 0.7915\n",
      "Epoch 29/100\n",
      "1594/1594 [==============================] - 0s 105us/step - loss: 0.7686 - acc: 0.7867 - val_loss: 0.7634 - val_acc: 0.7915\n",
      "Epoch 30/100\n",
      "1594/1594 [==============================] - 0s 107us/step - loss: 0.7677 - acc: 0.7867 - val_loss: 0.7624 - val_acc: 0.7915\n",
      "Epoch 31/100\n",
      "1594/1594 [==============================] - 0s 113us/step - loss: 0.7668 - acc: 0.7867 - val_loss: 0.7615 - val_acc: 0.7915\n",
      "Epoch 32/100\n",
      "1594/1594 [==============================] - 0s 111us/step - loss: 0.7661 - acc: 0.7867 - val_loss: 0.7608 - val_acc: 0.7915\n",
      "Epoch 33/100\n",
      "1594/1594 [==============================] - 0s 111us/step - loss: 0.7654 - acc: 0.7867 - val_loss: 0.7600 - val_acc: 0.7915\n",
      "Epoch 34/100\n",
      "1594/1594 [==============================] - 0s 108us/step - loss: 0.7647 - acc: 0.7867 - val_loss: 0.7594 - val_acc: 0.7915\n",
      "Epoch 35/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 0.7641 - acc: 0.7867 - val_loss: 0.7589 - val_acc: 0.7915\n",
      "Epoch 36/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.7636 - acc: 0.7867 - val_loss: 0.7583 - val_acc: 0.7915\n",
      "Epoch 37/100\n",
      "1594/1594 [==============================] - 0s 114us/step - loss: 0.7632 - acc: 0.7867 - val_loss: 0.7578 - val_acc: 0.7915\n",
      "Epoch 38/100\n",
      "1594/1594 [==============================] - 0s 108us/step - loss: 0.7627 - acc: 0.7867 - val_loss: 0.7574 - val_acc: 0.7915\n",
      "Epoch 39/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.7623 - acc: 0.7867 - val_loss: 0.7570 - val_acc: 0.7915\n",
      "Epoch 40/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 0.7620 - acc: 0.7867 - val_loss: 0.7566 - val_acc: 0.7915\n",
      "Epoch 41/100\n",
      "1594/1594 [==============================] - 0s 112us/step - loss: 0.7616 - acc: 0.7867 - val_loss: 0.7562 - val_acc: 0.7915\n",
      "Epoch 42/100\n",
      "1594/1594 [==============================] - 0s 112us/step - loss: 0.7613 - acc: 0.7867 - val_loss: 0.7559 - val_acc: 0.7915\n",
      "Epoch 43/100\n",
      "1594/1594 [==============================] - 0s 114us/step - loss: 0.7610 - acc: 0.7867 - val_loss: 0.7556 - val_acc: 0.7915\n",
      "Epoch 44/100\n",
      "1594/1594 [==============================] - 0s 112us/step - loss: 0.7607 - acc: 0.7867 - val_loss: 0.7553 - val_acc: 0.7915\n",
      "Epoch 45/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 0.7604 - acc: 0.7867 - val_loss: 0.7550 - val_acc: 0.7915\n",
      "Epoch 46/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 0.7601 - acc: 0.7867 - val_loss: 0.7548 - val_acc: 0.7915\n",
      "Epoch 47/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.7599 - acc: 0.7867 - val_loss: 0.7545 - val_acc: 0.7915\n",
      "Epoch 48/100\n",
      "1594/1594 [==============================] - 0s 111us/step - loss: 0.7597 - acc: 0.7867 - val_loss: 0.7543 - val_acc: 0.7915\n",
      "Epoch 49/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.7594 - acc: 0.7867 - val_loss: 0.7541 - val_acc: 0.7915\n",
      "Epoch 50/100\n",
      "1594/1594 [==============================] - 0s 108us/step - loss: 0.7592 - acc: 0.7867 - val_loss: 0.7538 - val_acc: 0.7915\n",
      "Epoch 51/100\n",
      "1594/1594 [==============================] - 0s 113us/step - loss: 0.7590 - acc: 0.7867 - val_loss: 0.7536 - val_acc: 0.7915\n",
      "Epoch 52/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.7588 - acc: 0.7867 - val_loss: 0.7534 - val_acc: 0.7915\n",
      "Epoch 53/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 0.7585 - acc: 0.7867 - val_loss: 0.7532 - val_acc: 0.7915\n",
      "Epoch 54/100\n",
      "1594/1594 [==============================] - 0s 130us/step - loss: 0.7584 - acc: 0.7867 - val_loss: 0.7530 - val_acc: 0.7915\n",
      "Epoch 55/100\n",
      "1594/1594 [==============================] - 0s 119us/step - loss: 0.7581 - acc: 0.7867 - val_loss: 0.7528 - val_acc: 0.7915\n",
      "Epoch 56/100\n",
      "1594/1594 [==============================] - 0s 121us/step - loss: 0.7580 - acc: 0.7867 - val_loss: 0.7526 - val_acc: 0.7915\n",
      "Epoch 57/100\n",
      "1594/1594 [==============================] - 0s 123us/step - loss: 0.7578 - acc: 0.7867 - val_loss: 0.7524 - val_acc: 0.7915\n",
      "Epoch 58/100\n",
      "1594/1594 [==============================] - 0s 111us/step - loss: 0.7576 - acc: 0.7867 - val_loss: 0.7523 - val_acc: 0.7915\n",
      "Epoch 59/100\n",
      "1594/1594 [==============================] - 0s 116us/step - loss: 0.7574 - acc: 0.7867 - val_loss: 0.7521 - val_acc: 0.7915\n",
      "Epoch 60/100\n",
      "1594/1594 [==============================] - 0s 118us/step - loss: 0.7572 - acc: 0.7867 - val_loss: 0.7519 - val_acc: 0.7915\n",
      "Epoch 61/100\n",
      "1594/1594 [==============================] - 0s 116us/step - loss: 0.7571 - acc: 0.7867 - val_loss: 0.7518 - val_acc: 0.7915\n",
      "Epoch 62/100\n",
      "1594/1594 [==============================] - 0s 115us/step - loss: 0.7569 - acc: 0.7867 - val_loss: 0.7516 - val_acc: 0.7915\n",
      "Epoch 63/100\n",
      "1594/1594 [==============================] - 0s 107us/step - loss: 0.7568 - acc: 0.7867 - val_loss: 0.7515 - val_acc: 0.7915\n",
      "Epoch 64/100\n",
      "1594/1594 [==============================] - 0s 114us/step - loss: 0.7566 - acc: 0.7867 - val_loss: 0.7513 - val_acc: 0.7915\n",
      "Epoch 65/100\n",
      "1594/1594 [==============================] - 0s 111us/step - loss: 0.7564 - acc: 0.7867 - val_loss: 0.7512 - val_acc: 0.7915\n",
      "Epoch 66/100\n",
      "1594/1594 [==============================] - 0s 108us/step - loss: 0.7562 - acc: 0.7867 - val_loss: 0.7510 - val_acc: 0.7915\n",
      "Epoch 67/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 0.7561 - acc: 0.7867 - val_loss: 0.7509 - val_acc: 0.7915\n",
      "Epoch 68/100\n",
      "1594/1594 [==============================] - 0s 115us/step - loss: 0.7559 - acc: 0.7867 - val_loss: 0.7507 - val_acc: 0.7915\n",
      "Epoch 69/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 0.7558 - acc: 0.7867 - val_loss: 0.7506 - val_acc: 0.7915\n",
      "Epoch 70/100\n",
      "1594/1594 [==============================] - 0s 123us/step - loss: 0.7556 - acc: 0.7867 - val_loss: 0.7504 - val_acc: 0.7915\n",
      "Epoch 71/100\n",
      "1594/1594 [==============================] - 0s 149us/step - loss: 0.7555 - acc: 0.7867 - val_loss: 0.7503 - val_acc: 0.7915\n",
      "Epoch 72/100\n",
      "1594/1594 [==============================] - 0s 125us/step - loss: 0.7553 - acc: 0.7867 - val_loss: 0.7502 - val_acc: 0.7915\n",
      "Epoch 73/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.7551 - acc: 0.7867 - val_loss: 0.7500 - val_acc: 0.7915\n",
      "Epoch 74/100\n",
      "1594/1594 [==============================] - 0s 146us/step - loss: 0.7550 - acc: 0.7867 - val_loss: 0.7499 - val_acc: 0.7915\n",
      "Epoch 75/100\n",
      "1594/1594 [==============================] - 0s 149us/step - loss: 0.7548 - acc: 0.7867 - val_loss: 0.7497 - val_acc: 0.7915\n",
      "Epoch 76/100\n",
      "1594/1594 [==============================] - 0s 142us/step - loss: 0.7547 - acc: 0.7867 - val_loss: 0.7496 - val_acc: 0.7915\n",
      "Epoch 77/100\n",
      "1594/1594 [==============================] - 0s 126us/step - loss: 0.7545 - acc: 0.7867 - val_loss: 0.7495 - val_acc: 0.7915\n",
      "Epoch 78/100\n",
      "1594/1594 [==============================] - 0s 114us/step - loss: 0.7544 - acc: 0.7867 - val_loss: 0.7493 - val_acc: 0.7915\n",
      "Epoch 79/100\n",
      "1594/1594 [==============================] - 0s 146us/step - loss: 0.7542 - acc: 0.7867 - val_loss: 0.7492 - val_acc: 0.7915\n",
      "Epoch 80/100\n",
      "1594/1594 [==============================] - 0s 142us/step - loss: 0.7541 - acc: 0.7867 - val_loss: 0.7490 - val_acc: 0.7915\n",
      "Epoch 81/100\n",
      "1594/1594 [==============================] - 0s 126us/step - loss: 0.7539 - acc: 0.7867 - val_loss: 0.7489 - val_acc: 0.7915\n",
      "Epoch 82/100\n",
      "1594/1594 [==============================] - 0s 130us/step - loss: 0.7538 - acc: 0.7867 - val_loss: 0.7488 - val_acc: 0.7915\n",
      "Epoch 83/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.7536 - acc: 0.7867 - val_loss: 0.7486 - val_acc: 0.7915\n",
      "Epoch 84/100\n",
      "1594/1594 [==============================] - 0s 151us/step - loss: 0.7534 - acc: 0.7867 - val_loss: 0.7485 - val_acc: 0.7915\n",
      "Epoch 85/100\n",
      "1594/1594 [==============================] - ETA: 0s - loss: 0.7559 - acc: 0.784 - 0s 125us/step - loss: 0.7533 - acc: 0.7867 - val_loss: 0.7484 - val_acc: 0.7915\n",
      "Epoch 86/100\n",
      "1594/1594 [==============================] - 0s 112us/step - loss: 0.7531 - acc: 0.7867 - val_loss: 0.7482 - val_acc: 0.7915\n",
      "Epoch 87/100\n",
      "1594/1594 [==============================] - 0s 117us/step - loss: 0.7530 - acc: 0.7867 - val_loss: 0.7481 - val_acc: 0.7915\n",
      "Epoch 88/100\n",
      "1594/1594 [==============================] - 0s 114us/step - loss: 0.7528 - acc: 0.7867 - val_loss: 0.7479 - val_acc: 0.7915\n",
      "Epoch 89/100\n",
      "1594/1594 [==============================] - 0s 121us/step - loss: 0.7527 - acc: 0.7867 - val_loss: 0.7478 - val_acc: 0.7915\n",
      "Epoch 90/100\n",
      "1594/1594 [==============================] - 0s 133us/step - loss: 0.7525 - acc: 0.7867 - val_loss: 0.7477 - val_acc: 0.7915\n",
      "Epoch 91/100\n",
      "1594/1594 [==============================] - 0s 147us/step - loss: 0.7524 - acc: 0.7867 - val_loss: 0.7476 - val_acc: 0.7915\n",
      "Epoch 92/100\n",
      "1594/1594 [==============================] - 0s 152us/step - loss: 0.7522 - acc: 0.7867 - val_loss: 0.7474 - val_acc: 0.7915\n",
      "Epoch 93/100\n",
      "1594/1594 [==============================] - 0s 131us/step - loss: 0.7521 - acc: 0.7867 - val_loss: 0.7473 - val_acc: 0.7915\n",
      "Epoch 94/100\n",
      "1594/1594 [==============================] - 0s 116us/step - loss: 0.7519 - acc: 0.7867 - val_loss: 0.7471 - val_acc: 0.7915\n",
      "Epoch 95/100\n",
      "1594/1594 [==============================] - 0s 113us/step - loss: 0.7518 - acc: 0.7867 - val_loss: 0.7470 - val_acc: 0.7915\n",
      "Epoch 96/100\n",
      "1594/1594 [==============================] - 0s 123us/step - loss: 0.7516 - acc: 0.7867 - val_loss: 0.7469 - val_acc: 0.7915\n",
      "Epoch 97/100\n",
      "1594/1594 [==============================] - 0s 130us/step - loss: 0.7515 - acc: 0.7867 - val_loss: 0.7468 - val_acc: 0.7915\n",
      "Epoch 98/100\n",
      "1594/1594 [==============================] - 0s 117us/step - loss: 0.7513 - acc: 0.7867 - val_loss: 0.7466 - val_acc: 0.7915\n",
      "Epoch 99/100\n",
      "1594/1594 [==============================] - 0s 128us/step - loss: 0.7512 - acc: 0.7867 - val_loss: 0.7465 - val_acc: 0.7915\n",
      "Epoch 100/100\n",
      "1594/1594 [==============================] - 0s 115us/step - loss: 0.7510 - acc: 0.7867 - val_loss: 0.7464 - val_acc: 0.7915\n",
      "499/499 [==============================] - 0s 52us/step\n",
      "Test score: 0.7799930150857669\n",
      "Test accuracy: 0.7655310672605204\n"
     ]
    }
   ],
   "source": [
    "# Fit Model B2\n",
    "\n",
    "histb2 = fit_model(modelb2, x_train, y_train, \\\n",
    "                          x_val, y_val, \\\n",
    "                          x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:22:31.096210Z",
     "start_time": "2020-10-19T16:22:30.962074Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "MSw4fbHCUy79",
    "outputId": "b14dd609-6150-4d26-9783-c38886d93050"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYIwxpoIlBWOMMRUsKRhjjKnw/2v0KpG7G46fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27f02f6fbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot validation loss curves\n",
    "\n",
    "# add your code here\n",
    "epochs=list(range(0,100))\n",
    "\n",
    "val_loss_B = histb.history['val_loss']\n",
    "val_loss_B1 = histb1.history['val_loss']\n",
    "val_loss_B2 = histb2.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, val_loss_B, 'r', label='Model B')\n",
    "plt.plot(epochs, val_loss_B1, 'g', label='Model B1')\n",
    "plt.plot(epochs, val_loss_B2, 'b', label='Model B2')\n",
    "\n",
    "plt.title('Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epochs)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:22:32.471264Z",
     "start_time": "2020-10-19T16:22:32.340698Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "COxUGbyWUy7_",
    "outputId": "fef6986d-1735-41a5-861b-8926639645c5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27f031647f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot validation accuracy curves\n",
    "epochs=list(range(0,100))\n",
    "# add your code here\n",
    "val_acc_B = histb.history['val_acc']\n",
    "val_acc_B1 = histb1.history['val_acc']\n",
    "val_acc_B2 = histb2.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, val_acc_B, 'r', label='Model B')\n",
    "plt.plot(epochs, val_acc_B1, 'g', label='Model B1')\n",
    "plt.plot(epochs, val_acc_B2, 'b', label='Model B2')\n",
    "\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(epochs)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis \n",
    "\n",
    "1.Did any of the strategies improve model performance on the test dataset?\n",
    "- Yes， but not obvious.\n",
    "\n",
    "2.For each regularized model, did you still observe overfitting? In this case, which strategy is the most effective in reducing overfing?tti\n",
    "- No. maybe modelB1 using dropout have better performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PohsTF1tUy8B"
   },
   "source": [
    "### Task 4: Create neural network model for regression task \n",
    "- In this task, let's create a model to predict specific `worry` level (`1-9`) using `text_short` column. Let's consider this as a `regression` task instead of classification, because it would be difficult to differenitate levels precisely (e.g. levels 4 and 5). We'd like to predict a level which can be close to the target level as much as possible.\n",
    "- Let's reuse the best models you achieved for Task 1 and Task 2. Modify these models to for the regression task. Also, modify the `fit_model` function accordingly. Specifically, you need to modify:\n",
    "  - Activation function of the output layer\n",
    "  - Loss function \n",
    "- Similarly, split the samples to training, test, evaluation subsets as before. Note, for this task, the target is `worry` column in the dataset\n",
    "- After training, use the model to predict <font color=red>'worry'</font> on the test subset and print out the test loss.\n",
    "- Plot validation loss vs. epoches from the training histories of these models\n",
    "- Did the regularization strategy improves model performance on the validation dataset? Write your analysis (as markdowns)\n",
    "- `Note, due to randomness, you may observe different results in each round. You just need to analyze based on one round of the results you obtained`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:22:39.424140Z",
     "start_time": "2020-10-19T16:22:39.404132Z"
    },
    "collapsed": true,
    "id": "xgb6bcYUUy8C"
   },
   "outputs": [],
   "source": [
    "# Define model with regularization\n",
    "\n",
    "# add your code here\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(units=128, activation='relu',input_dim =4402 ))   \n",
    "model3.add(Dense(units=32, activation='relu'))\n",
    "model3.add(Dense(units=1)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:22:41.056196Z",
     "start_time": "2020-10-19T16:22:41.052196Z"
    },
    "collapsed": true,
    "id": "ncUmFx72Uy8F"
   },
   "outputs": [],
   "source": [
    "# Define model with regularization\n",
    "\n",
    "# add your code here\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(units=128, activation='relu',input_dim =4402,activity_regularizer=regularizers.l1(0.01)))   \n",
    "model4.add(Dense(units=32, activation='relu'))\n",
    "model4.add(Dense(units=1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:23:17.336096Z",
     "start_time": "2020-10-19T16:23:17.332055Z"
    },
    "collapsed": true,
    "id": "4_eMePxMUy8I"
   },
   "outputs": [],
   "source": [
    "# Define fit_model function\n",
    "def fit_model(model, x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "    \n",
    "    history = None\n",
    "    \n",
    "    model.compile(optimizer='sgd',loss='mean_squared_error')\n",
    "\n",
    "    history = model.fit(x_train, y_train, validation_data = (x_val, y_val),\n",
    "                    batch_size=128,\n",
    "                    epochs=100,\n",
    "                    verbose=1)\n",
    "    \n",
    "    # please print out the performance on test subset\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, batch_size=128,\n",
    "                        verbose=1)\n",
    "    print('Test loss:', score)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:23:17.805003Z",
     "start_time": "2020-10-19T16:23:17.709133Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1vl2QK9pUy8K",
    "outputId": "b5754c02-5973-41a6-88d9-19dc11e46181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1594,) (499,)\n"
     ]
    }
   ],
   "source": [
    "# split data into training, evaluation, and test subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    " # add your code here\n",
    "train_x_1 =  df_tfidfvect.iloc[:int(df_tfidfvect.shape[0] * 0.8), :]\n",
    "x_test=  np.array(df_tfidfvect.iloc[int(df_tfidfvect.shape[0] * 0.8):, :])\n",
    "train_y_1 = data.iloc[:int(data.shape[0] * 0.8), 1]\n",
    "y_test= np.array(data.iloc[int(data.shape[0] * 0.8):, 1])\n",
    "\n",
    "x_val = np.array(train_x_1[:int(train_x_1.shape[0] * 0.2)])\n",
    "x_train = np.array(train_x_1[int(train_x_1.shape[0] * 0.2):])\n",
    "x_val.shape\n",
    "\n",
    "y_val = np.array(train_y_1[:int(train_y_1.shape[0] * 0.2)])\n",
    "y_train = np.array(train_y_1[int(train_y_1.shape[0] * 0.2):])\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:23:31.120847Z",
     "start_time": "2020-10-19T16:23:18.125983Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "JYfs6AaKUy8M",
    "outputId": "0a235bd2-7b04-4914-e835-d1c8853ca563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1594 samples, validate on 398 samples\n",
      "Epoch 1/100\n",
      "1594/1594 [==============================] - 1s 634us/step - loss: 2.9483 - val_loss: 2.8717\n",
      "Epoch 2/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 2.9226 - val_loss: 2.9506\n",
      "Epoch 3/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 2.9191 - val_loss: 2.8290\n",
      "Epoch 4/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 2.9107 - val_loss: 2.8177\n",
      "Epoch 5/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 2.8957 - val_loss: 2.8454\n",
      "Epoch 6/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 2.8736 - val_loss: 2.8025\n",
      "Epoch 7/100\n",
      "1594/1594 [==============================] - 0s 92us/step - loss: 2.8564 - val_loss: 2.8289\n",
      "Epoch 8/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 2.8510 - val_loss: 2.7686\n",
      "Epoch 9/100\n",
      "1594/1594 [==============================] - 0s 88us/step - loss: 2.8420 - val_loss: 3.0374\n",
      "Epoch 10/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 2.8135 - val_loss: 2.7890\n",
      "Epoch 11/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 2.7966 - val_loss: 2.8544\n",
      "Epoch 12/100\n",
      "1594/1594 [==============================] - 0s 95us/step - loss: 2.7770 - val_loss: 2.7565\n",
      "Epoch 13/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 2.7618 - val_loss: 3.0756\n",
      "Epoch 14/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 2.7587 - val_loss: 2.7790\n",
      "Epoch 15/100\n",
      "1594/1594 [==============================] - 0s 92us/step - loss: 2.7529 - val_loss: 2.8381\n",
      "Epoch 16/100\n",
      "1594/1594 [==============================] - 0s 85us/step - loss: 2.7082 - val_loss: 2.7924\n",
      "Epoch 17/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 2.6932 - val_loss: 2.8303\n",
      "Epoch 18/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 2.6776 - val_loss: 2.7416\n",
      "Epoch 19/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 2.6530 - val_loss: 2.8136\n",
      "Epoch 20/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 2.6382 - val_loss: 2.6959\n",
      "Epoch 21/100\n",
      "1594/1594 [==============================] - 0s 92us/step - loss: 2.6478 - val_loss: 2.6923\n",
      "Epoch 22/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 2.5903 - val_loss: 2.7741\n",
      "Epoch 23/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 2.5786 - val_loss: 2.7888\n",
      "Epoch 24/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 2.5427 - val_loss: 2.7261\n",
      "Epoch 25/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 2.5224 - val_loss: 2.6756\n",
      "Epoch 26/100\n",
      "1594/1594 [==============================] - 0s 90us/step - loss: 2.5190 - val_loss: 2.7747\n",
      "Epoch 27/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 2.4980 - val_loss: 2.7151\n",
      "Epoch 28/100\n",
      "1594/1594 [==============================] - 0s 88us/step - loss: 2.4607 - val_loss: 2.7676\n",
      "Epoch 29/100\n",
      "1594/1594 [==============================] - 0s 92us/step - loss: 2.4612 - val_loss: 2.8958\n",
      "Epoch 30/100\n",
      "1594/1594 [==============================] - 0s 87us/step - loss: 2.4372 - val_loss: 2.6950\n",
      "Epoch 31/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 2.4066 - val_loss: 2.8481\n",
      "Epoch 32/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 2.3704 - val_loss: 2.6812\n",
      "Epoch 33/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 2.3376 - val_loss: 2.6411\n",
      "Epoch 34/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 2.3289 - val_loss: 2.7680\n",
      "Epoch 35/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 2.3062 - val_loss: 2.6918\n",
      "Epoch 36/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 2.2712 - val_loss: 2.6587\n",
      "Epoch 37/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 2.2493 - val_loss: 2.6273\n",
      "Epoch 38/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 2.2225 - val_loss: 2.7025\n",
      "Epoch 39/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 2.1906 - val_loss: 2.6314\n",
      "Epoch 40/100\n",
      "1594/1594 [==============================] - 0s 95us/step - loss: 2.1911 - val_loss: 2.6502\n",
      "Epoch 41/100\n",
      "1594/1594 [==============================] - 0s 88us/step - loss: 2.1715 - val_loss: 2.6628\n",
      "Epoch 42/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 2.1204 - val_loss: 2.6427\n",
      "Epoch 43/100\n",
      "1594/1594 [==============================] - 0s 88us/step - loss: 2.0705 - val_loss: 3.0420\n",
      "Epoch 44/100\n",
      "1594/1594 [==============================] - 0s 88us/step - loss: 2.0723 - val_loss: 2.6951\n",
      "Epoch 45/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 2.0218 - val_loss: 2.8889\n",
      "Epoch 46/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 2.0165 - val_loss: 2.6457\n",
      "Epoch 47/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 2.0065 - val_loss: 2.8873\n",
      "Epoch 48/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 1.9449 - val_loss: 2.6645\n",
      "Epoch 49/100\n",
      "1594/1594 [==============================] - 0s 90us/step - loss: 1.9205 - val_loss: 2.6650\n",
      "Epoch 50/100\n",
      "1594/1594 [==============================] - 0s 90us/step - loss: 1.8812 - val_loss: 2.6485\n",
      "Epoch 51/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 1.8588 - val_loss: 2.6962\n",
      "Epoch 52/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 1.8530 - val_loss: 2.6559\n",
      "Epoch 53/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 1.9010 - val_loss: 2.7277\n",
      "Epoch 54/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 1.8333 - val_loss: 3.5212\n",
      "Epoch 55/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 1.7970 - val_loss: 2.6828\n",
      "Epoch 56/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 1.7441 - val_loss: 2.7876\n",
      "Epoch 57/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 1.6952 - val_loss: 2.7073\n",
      "Epoch 58/100\n",
      "1594/1594 [==============================] - 0s 87us/step - loss: 1.6760 - val_loss: 2.6897\n",
      "Epoch 59/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 1.7407 - val_loss: 2.8143\n",
      "Epoch 60/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 1.6961 - val_loss: 2.7184\n",
      "Epoch 61/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 1.6649 - val_loss: 2.8221\n",
      "Epoch 62/100\n",
      "1594/1594 [==============================] - 0s 92us/step - loss: 1.6528 - val_loss: 2.7416\n",
      "Epoch 63/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 1.9440 - val_loss: 3.4001\n",
      "Epoch 64/100\n",
      "1594/1594 [==============================] - 0s 83us/step - loss: 2.6195 - val_loss: 3.0505\n",
      "Epoch 65/100\n",
      "1594/1594 [==============================] - 0s 86us/step - loss: 1.6144 - val_loss: 2.7272\n",
      "Epoch 66/100\n",
      "1594/1594 [==============================] - 0s 84us/step - loss: 1.5198 - val_loss: 3.2308\n",
      "Epoch 67/100\n",
      "1594/1594 [==============================] - 0s 88us/step - loss: 1.9818 - val_loss: 2.8166\n",
      "Epoch 68/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 1.4659 - val_loss: 2.8325\n",
      "Epoch 69/100\n",
      "1594/1594 [==============================] - 0s 111us/step - loss: 1.7397 - val_loss: 4.0606\n",
      "Epoch 70/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 2.5149 - val_loss: 3.0837\n",
      "Epoch 71/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 2.0052 - val_loss: 3.7126\n",
      "Epoch 72/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 1.9696 - val_loss: 2.9802\n",
      "Epoch 73/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 1.3965 - val_loss: 2.8581\n",
      "Epoch 74/100\n",
      "1594/1594 [==============================] - 0s 88us/step - loss: 1.4497 - val_loss: 2.9493\n",
      "Epoch 75/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 1.7064 - val_loss: 4.9233\n",
      "Epoch 76/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 1.5464 - val_loss: 2.8238\n",
      "Epoch 77/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 1.3718 - val_loss: 2.8049\n",
      "Epoch 78/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 2.7246 - val_loss: 6.5996\n",
      "Epoch 79/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 1.9687 - val_loss: 2.9095\n",
      "Epoch 80/100\n",
      "1594/1594 [==============================] - 0s 88us/step - loss: 1.5214 - val_loss: 2.9120\n",
      "Epoch 81/100\n",
      "1594/1594 [==============================] - 0s 84us/step - loss: 1.6118 - val_loss: 3.2049\n",
      "Epoch 82/100\n",
      "1594/1594 [==============================] - 0s 84us/step - loss: 1.3847 - val_loss: 2.9596\n",
      "Epoch 83/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 1.7523 - val_loss: 3.0455\n",
      "Epoch 84/100\n",
      "1594/1594 [==============================] - 0s 84us/step - loss: 1.2767 - val_loss: 3.0594\n",
      "Epoch 85/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 1.6961 - val_loss: 4.2082\n",
      "Epoch 86/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 2.5369 - val_loss: 4.3614\n",
      "Epoch 87/100\n",
      "1594/1594 [==============================] - 0s 84us/step - loss: 1.3763 - val_loss: 2.9098\n",
      "Epoch 88/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 1.6089 - val_loss: 2.8114\n",
      "Epoch 89/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 1.8100 - val_loss: 3.5015\n",
      "Epoch 90/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 1.5714 - val_loss: 3.0231\n",
      "Epoch 91/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 1.7736 - val_loss: 3.0900\n",
      "Epoch 92/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 1.7038 - val_loss: 2.9075\n",
      "Epoch 93/100\n",
      "1594/1594 [==============================] - 0s 95us/step - loss: 1.2983 - val_loss: 3.4805\n",
      "Epoch 94/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 2.0194 - val_loss: 2.9460\n",
      "Epoch 95/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 1.6992 - val_loss: 3.1097\n",
      "Epoch 96/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 1.7727 - val_loss: 2.8934\n",
      "Epoch 97/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 1.1377 - val_loss: 2.9007\n",
      "Epoch 98/100\n",
      "1594/1594 [==============================] - 0s 86us/step - loss: 1.1498 - val_loss: 3.7038\n",
      "Epoch 99/100\n",
      "1594/1594 [==============================] - 0s 87us/step - loss: 1.7468 - val_loss: 5.3851\n",
      "Epoch 100/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 2.0077 - val_loss: 2.8561\n",
      "499/499 [==============================] - 0s 46us/step\n",
      "Test loss: 3.354814067393362\n"
     ]
    }
   ],
   "source": [
    "hist3 = fit_model(model3, x_train, y_train, \\\n",
    "                          x_val, y_val, \\\n",
    "                          x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:23:49.039988Z",
     "start_time": "2020-10-19T16:23:31.122848Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7v2W1PpmUy8P",
    "outputId": "b9560a04-da3a-4058-dfa5-62ca8f4e0c64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1594 samples, validate on 398 samples\n",
      "Epoch 1/100\n",
      "1594/1594 [==============================] - 1s 723us/step - loss: 28.6251 - val_loss: 9.2739\n",
      "Epoch 2/100\n",
      "1594/1594 [==============================] - 0s 113us/step - loss: 6.3785 - val_loss: 4.9607\n",
      "Epoch 3/100\n",
      "1594/1594 [==============================] - 0s 116us/step - loss: 4.4072 - val_loss: 3.9180\n",
      "Epoch 4/100\n",
      "1594/1594 [==============================] - 0s 138us/step - loss: 3.6402 - val_loss: 3.3094\n",
      "Epoch 5/100\n",
      "1594/1594 [==============================] - 0s 137us/step - loss: 3.2785 - val_loss: 3.0502\n",
      "Epoch 6/100\n",
      "1594/1594 [==============================] - 0s 126us/step - loss: 3.1304 - val_loss: 3.0094\n",
      "Epoch 7/100\n",
      "1594/1594 [==============================] - 0s 117us/step - loss: 3.1121 - val_loss: 2.9788\n",
      "Epoch 8/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 3.1081 - val_loss: 3.0008\n",
      "Epoch 9/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 3.1054 - val_loss: 2.9837\n",
      "Epoch 10/100\n",
      "1594/1594 [==============================] - 0s 95us/step - loss: 3.1064 - val_loss: 2.9711\n",
      "Epoch 11/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 3.1031 - val_loss: 2.9582\n",
      "Epoch 12/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 3.1011 - val_loss: 2.9751\n",
      "Epoch 13/100\n",
      "1594/1594 [==============================] - 0s 108us/step - loss: 3.0970 - val_loss: 2.9981\n",
      "Epoch 14/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 3.0944 - val_loss: 3.0333\n",
      "Epoch 15/100\n",
      "1594/1594 [==============================] - 0s 105us/step - loss: 3.1010 - val_loss: 2.9593\n",
      "Epoch 16/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 3.0935 - val_loss: 2.9767\n",
      "Epoch 17/100\n",
      "1594/1594 [==============================] - 0s 108us/step - loss: 3.0934 - val_loss: 2.9423\n",
      "Epoch 18/100\n",
      "1594/1594 [==============================] - 0s 105us/step - loss: 3.0913 - val_loss: 2.9578\n",
      "Epoch 19/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 3.0865 - val_loss: 3.0254\n",
      "Epoch 20/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 3.0888 - val_loss: 2.9569\n",
      "Epoch 21/100\n",
      "1594/1594 [==============================] - 0s 116us/step - loss: 3.0857 - val_loss: 2.9906\n",
      "Epoch 22/100\n",
      "1594/1594 [==============================] - 0s 95us/step - loss: 3.0804 - val_loss: 2.9556\n",
      "Epoch 23/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 3.0766 - val_loss: 2.9359\n",
      "Epoch 24/100\n",
      "1594/1594 [==============================] - 0s 125us/step - loss: 3.0762 - val_loss: 2.9523\n",
      "Epoch 25/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 3.0784 - val_loss: 2.9596\n",
      "Epoch 26/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 3.0710 - val_loss: 3.0424\n",
      "Epoch 27/100\n",
      "1594/1594 [==============================] - 0s 105us/step - loss: 3.0737 - val_loss: 2.9934\n",
      "Epoch 28/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 3.0655 - val_loss: 2.9596\n",
      "Epoch 29/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 3.0599 - val_loss: 2.9930\n",
      "Epoch 30/100\n",
      "1594/1594 [==============================] - 0s 126us/step - loss: 3.0589 - val_loss: 3.0085\n",
      "Epoch 31/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 3.0522 - val_loss: 2.9629\n",
      "Epoch 32/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 3.0468 - val_loss: 2.9476\n",
      "Epoch 33/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 3.0489 - val_loss: 3.0069\n",
      "Epoch 34/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 3.0421 - val_loss: 2.9552\n",
      "Epoch 35/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 3.0420 - val_loss: 2.9562\n",
      "Epoch 36/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 3.0398 - val_loss: 2.9505\n",
      "Epoch 37/100\n",
      "1594/1594 [==============================] - 0s 118us/step - loss: 3.0288 - val_loss: 2.9634\n",
      "Epoch 38/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 3.0240 - val_loss: 2.9838\n",
      "Epoch 39/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 3.0224 - val_loss: 2.9612\n",
      "Epoch 40/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 3.0133 - val_loss: 2.9533\n",
      "Epoch 41/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 3.0106 - val_loss: 2.9336\n",
      "Epoch 42/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 3.0104 - val_loss: 2.9959\n",
      "Epoch 43/100\n",
      "1594/1594 [==============================] - 0s 95us/step - loss: 2.9963 - val_loss: 2.9962\n",
      "Epoch 44/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 2.9899 - val_loss: 2.9389\n",
      "Epoch 45/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 2.9802 - val_loss: 2.9089\n",
      "Epoch 46/100\n",
      "1594/1594 [==============================] - 0s 92us/step - loss: 2.9789 - val_loss: 2.9359\n",
      "Epoch 47/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 2.9708 - val_loss: 2.9836\n",
      "Epoch 48/100\n",
      "1594/1594 [==============================] - 0s 115us/step - loss: 2.9677 - val_loss: 2.8997\n",
      "Epoch 49/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 2.9542 - val_loss: 2.9206\n",
      "Epoch 50/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 2.9485 - val_loss: 2.9264\n",
      "Epoch 51/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 2.9335 - val_loss: 2.9006\n",
      "Epoch 52/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 2.9223 - val_loss: 2.9222\n",
      "Epoch 53/100\n",
      "1594/1594 [==============================] - 0s 115us/step - loss: 2.9250 - val_loss: 2.9243\n",
      "Epoch 54/100\n",
      "1594/1594 [==============================] - 0s 106us/step - loss: 2.9114 - val_loss: 2.9194\n",
      "Epoch 55/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 2.9028 - val_loss: 2.9165\n",
      "Epoch 56/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 2.8863 - val_loss: 2.8812\n",
      "Epoch 57/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 2.8954 - val_loss: 2.9105\n",
      "Epoch 58/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 2.8677 - val_loss: 2.9253\n",
      "Epoch 59/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 2.8544 - val_loss: 2.8890\n",
      "Epoch 60/100\n",
      "1594/1594 [==============================] - 0s 108us/step - loss: 2.8421 - val_loss: 2.8955\n",
      "Epoch 61/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 2.8459 - val_loss: 2.8919\n",
      "Epoch 62/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 2.8260 - val_loss: 2.8680\n",
      "Epoch 63/100\n",
      "1594/1594 [==============================] - 0s 102us/step - loss: 2.8248 - val_loss: 2.9475\n",
      "Epoch 64/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 2.7912 - val_loss: 2.8882\n",
      "Epoch 65/100\n",
      "1594/1594 [==============================] - 0s 105us/step - loss: 2.7931 - val_loss: 2.8896\n",
      "Epoch 66/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 2.7594 - val_loss: 2.8700\n",
      "Epoch 67/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 2.7611 - val_loss: 2.8505\n",
      "Epoch 68/100\n",
      "1594/1594 [==============================] - 0s 104us/step - loss: 2.7359 - val_loss: 2.8915\n",
      "Epoch 69/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 2.7247 - val_loss: 2.8587\n",
      "Epoch 70/100\n",
      "1594/1594 [==============================] - 0s 99us/step - loss: 2.7001 - val_loss: 2.8636\n",
      "Epoch 71/100\n",
      "1594/1594 [==============================] - 0s 88us/step - loss: 2.6965 - val_loss: 2.8804\n",
      "Epoch 72/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 2.6715 - val_loss: 2.8947\n",
      "Epoch 73/100\n",
      "1594/1594 [==============================] - 0s 92us/step - loss: 2.6549 - val_loss: 2.8490\n",
      "Epoch 74/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 2.6390 - val_loss: 2.8625\n",
      "Epoch 75/100\n",
      "1594/1594 [==============================] - 0s 95us/step - loss: 2.6323 - val_loss: 2.8460\n",
      "Epoch 76/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 2.6040 - val_loss: 2.8399\n",
      "Epoch 77/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 2.5697 - val_loss: 2.8659\n",
      "Epoch 78/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 2.5824 - val_loss: 2.9444\n",
      "Epoch 79/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 2.5390 - val_loss: 2.8218\n",
      "Epoch 80/100\n",
      "1594/1594 [==============================] - 0s 168us/step - loss: 2.5529 - val_loss: 2.8355\n",
      "Epoch 81/100\n",
      "1594/1594 [==============================] - 0s 92us/step - loss: 2.5185 - val_loss: 2.8646\n",
      "Epoch 82/100\n",
      "1594/1594 [==============================] - 0s 98us/step - loss: 2.4963 - val_loss: 2.8381\n",
      "Epoch 83/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 2.4834 - val_loss: 2.8257\n",
      "Epoch 84/100\n",
      "1594/1594 [==============================] - 0s 91us/step - loss: 2.4502 - val_loss: 2.8996\n",
      "Epoch 85/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 2.4397 - val_loss: 2.8684\n",
      "Epoch 86/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 2.4002 - val_loss: 2.9047\n",
      "Epoch 87/100\n",
      "1594/1594 [==============================] - 0s 89us/step - loss: 2.4069 - val_loss: 2.8356\n",
      "Epoch 88/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 2.3423 - val_loss: 3.0718\n",
      "Epoch 89/100\n",
      "1594/1594 [==============================] - 0s 96us/step - loss: 2.3661 - val_loss: 2.8285\n",
      "Epoch 90/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 2.3564 - val_loss: 2.8641\n",
      "Epoch 91/100\n",
      "1594/1594 [==============================] - 0s 103us/step - loss: 2.3249 - val_loss: 2.8918\n",
      "Epoch 92/100\n",
      "1594/1594 [==============================] - 0s 97us/step - loss: 2.2550 - val_loss: 3.3502\n",
      "Epoch 93/100\n",
      "1594/1594 [==============================] - 0s 93us/step - loss: 2.2551 - val_loss: 2.8407\n",
      "Epoch 94/100\n",
      "1594/1594 [==============================] - 0s 90us/step - loss: 2.2180 - val_loss: 2.8461\n",
      "Epoch 95/100\n",
      "1594/1594 [==============================] - 0s 94us/step - loss: 2.2593 - val_loss: 3.0312\n",
      "Epoch 96/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 2.2338 - val_loss: 2.8789\n",
      "Epoch 97/100\n",
      "1594/1594 [==============================] - 0s 100us/step - loss: 2.2650 - val_loss: 2.8692\n",
      "Epoch 98/100\n",
      "1594/1594 [==============================] - 0s 101us/step - loss: 2.1288 - val_loss: 3.3563\n",
      "Epoch 99/100\n",
      "1594/1594 [==============================] - 0s 109us/step - loss: 2.1894 - val_loss: 2.8790\n",
      "Epoch 100/100\n",
      "1594/1594 [==============================] - 0s 113us/step - loss: 2.1412 - val_loss: 3.0540\n",
      "499/499 [==============================] - 0s 50us/step\n",
      "Test loss: 3.7770032318894993\n"
     ]
    }
   ],
   "source": [
    "hist4 = fit_model(model4, x_train, y_train, \\\n",
    "                          x_val, y_val, \\\n",
    "                          x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T16:28:17.488841Z",
     "start_time": "2020-10-19T16:28:17.363464Z"
    },
    "id": "vYnmlds1Uy8R",
    "outputId": "1fcc8d60-c926-4140-dde6-f32a5ea575b9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27f030b8978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot evaluation performance of two models\n",
    "\n",
    "# add your code here\n",
    "epochs=list(range(0,100))\n",
    "\n",
    "val_loss_3 = hist3.history['val_loss']\n",
    "val_loss_4 = hist4.history['val_loss']\n",
    "\n",
    "\n",
    "plt.plot( epochs,val_loss_3, 'r', label='Basic Regression')\n",
    "plt.plot( epochs,val_loss_4, 'g', label='Regression with regularization')\n",
    "\n",
    "plt.title('Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.xticks(epochs)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "DPmLQPDOUy8U"
   },
   "source": [
    "Analysis \n",
    "1.Did the regularization strategy improves model performance on the validation dataset?\n",
    "- Yes. The regularization strategy imporves model perfomance. From the picture, we can find the loss of regression with regularization beter than other one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW2 (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
